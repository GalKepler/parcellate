{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#parcellate","title":"parcellate","text":"<p><code>parcellate</code> is a BIDS App for extracting regional statistics from scalar neuroimaging maps using atlas-based parcellation. It integrates with CAT12 (VBM) and QSIRecon (dMRI) preprocessing pipelines and produces tidy TSV tables suitable for downstream analysis and quality control.</p> <ul> <li> <p>Quick start</p> <p>Install the package, configure your environment, and run your first parcellation.</p> <p> Getting started</p> </li> <li> <p>CAT12 guide</p> <p>Process CAT12 VBM outputs: input layout, output format, masking, and TIV.</p> <p> CAT12 pipeline guide</p> </li> <li> <p>QSIRecon guide</p> <p>Process QSIRecon diffusion outputs including 4D probabilistic atlases.</p> <p> QSIRecon pipeline guide</p> </li> <li> <p>API reference</p> <p>Explore the VolumetricParcellator and the built-in statistical functions.</p> <p> API</p> </li> </ul>"},{"location":"api/","title":"API reference","text":"<p>The reference below is generated from the public Python API. Functions and classes inherit docstrings directly from the source code to keep behavior descriptions synchronized.</p>"},{"location":"api/#core-parcellator","title":"Core parcellator","text":""},{"location":"api/#parcellate.parcellation.volume","title":"<code>volume</code>","text":""},{"location":"api/#parcellate.parcellation.volume.VolumetricParcellator","title":"<code>VolumetricParcellator</code>","text":"<p>Base volumetric parcellator.</p> <p>The parcellator assumes an integer-valued atlas where each non-background voxel stores the parcel identifier. Parcellation is performed by sampling a scalar map image and aggregating values inside each region. Resampling to the atlas grid is handled by default to keep atlas boundaries consistent across inputs.</p> Source code in <code>src/parcellate/parcellation/volume.py</code> <pre><code>class VolumetricParcellator:\n    \"\"\"Base volumetric parcellator.\n\n    The parcellator assumes an integer-valued atlas where each non-background\n    voxel stores the parcel identifier. Parcellation is performed by sampling a\n    scalar map image and aggregating values inside each region. Resampling to\n    the atlas grid is handled by default to keep atlas boundaries consistent\n    across inputs.\n    \"\"\"\n\n    REQUIRED_LUT_COLUMNS: ClassVar[set[str]] = {\"index\", \"label\"}\n    BUILTIN_STANDARD_MASKS: ClassVar[Mapping[str, str]] = {\n        \"gm\": load_mni152_gm_mask,\n        \"wm\": load_mni152_wm_mask,\n        \"brain\": load_mni152_brain_mask,\n    }\n\n    def __init__(\n        self,\n        atlas_img: nib.Nifti1Image | str | Path,\n        labels: Mapping[int, str] | Sequence[str] | None = None,\n        lut: pd.DataFrame | str | Path | None = None,\n        *,\n        mask: nib.Nifti1Image | str | Path | None = None,\n        mask_threshold: float = 0.0,\n        atlas_threshold: float = 0.0,\n        background_label: int = 0,\n        resampling_target: Literal[\"data\", \"labels\", \"atlas\", None] = \"data\",\n        stat_functions: Mapping[str, Callable[..., float]] | None = None,\n        stat_tier: str | None = None,\n    ) -&gt; None:\n        \"\"\"\n        Initialize a volumetric parcellator\n\n        Parameters\n        ----------\n        atlas_img : nib.Nifti1Image | str | Path\n            The atlas image defining the parcellation.\n        labels : Mapping[int, str] | Sequence[str] | None, optional\n            Region labels mapping or sequence, by default None\n        lut : pd.DataFrame | str | Path | None, optional\n            Lookup table for region labels, by default None. Must include columns\n            \"index\" and \"label\" following the BIDS standard.\n        mask : nib.Nifti1Image | str | Path | None, optional\n            Optional mask to apply to the atlas, by default None\n        mask_threshold : float, optional\n            Threshold for the mask image. Voxels with mask values strictly greater\n            than this threshold are included; all others are excluded. Default is\n            ``0.0``, which preserves the original behaviour of including every\n            non-zero voxel. Use values in [0, 1] for probability maps (e.g.\n            ``0.5`` to keep only voxels with &gt;50 % gray-matter probability).\n        atlas_threshold : float, optional\n            Threshold for probabilistic (4D) atlas volumes. Voxels with probability\n            strictly greater than this value are included in each region's mask.\n            Default is ``0.0`` (any non-zero probability voxel is included). Only\n            used when the atlas image is 4D. Ignored for 3D discrete atlases.\n        background_label : int, optional\n            Label value to treat as background, by default 0\n        resampling_target : Literal[\"data\", \"labels\", None], optional\n            Resampling target for input maps, by default \"data\"\n        stat_functions : Mapping[str, StatFunction] | None, optional\n            Mapping of statistic names to functions, by default None.\n            When provided, takes precedence over ``stat_tier``.\n        stat_tier : str | None, optional\n            Named statistics tier to use when ``stat_functions`` is ``None``.\n            Valid values: ``\"core\"``, ``\"extended\"``, ``\"diagnostic\"``, ``\"all\"``.\n            Defaults to ``None``, which selects all built-in statistics\n            (equivalent to ``\"diagnostic\"``).\n        \"\"\"\n        self.atlas_img = _load_nifti(atlas_img)\n        self.lut = self._load_atlas_lut(lut) if lut is not None else None\n        self.mask_threshold = float(mask_threshold)\n        self.atlas_threshold = float(atlas_threshold)\n        self.mask = self._load_mask(mask) if mask is not None else None\n        self.background_label = int(background_label)\n        self.resampling_target = resampling_target\n        self._atlas_data = self._load_atlas_data()\n        self._is_probabilistic = self._atlas_data.ndim == 4\n        self._regions = self._build_regions(labels)\n        self._stat_functions = self._prepare_stat_functions(stat_functions, stat_tier=stat_tier)\n        self._fitted_scalar_id: str | int | None = None\n\n    def _load_mask(self, mask: nib.Nifti1Image | str | Path) -&gt; nib.Nifti1Image:\n        \"\"\"\n        Load a mask image, supporting built-in standard masks.\n\n        Parameters\n        ----------\n        mask : nib.Nifti1Image | str | Path\n            Mask image to load.\n\n        Returns\n        -------\n        nib.Nifti1Image\n            Loaded mask image.\n        \"\"\"\n        if isinstance(mask, str) and mask in self.BUILTIN_STANDARD_MASKS:\n            return self.BUILTIN_STANDARD_MASKS[mask](threshold=self.mask_threshold)\n        return _load_nifti(mask)\n\n    def _get_labels(self, labels: Mapping[int, str] | Sequence[str] | None) -&gt; list[int]:\n        \"\"\"\n        Get labels from those required by the user and the ones from the lut/image\n\n        Parameters\n        ----------\n        labels : Mapping[int, str] | Sequence[str] | None\n            Labels provided by the user.\n\n        Returns\n        -------\n        list[int]\n            List of labels to use.\n        \"\"\"\n        if labels is not None:\n            if isinstance(labels, Mapping):\n                return list(labels.keys())\n            elif isinstance(labels, Sequence):\n                return list(labels)\n        if self.lut is not None:\n            return self.lut[\"index\"].tolist()\n        if self._atlas_data.ndim == 4:\n            return list(range(1, self._atlas_data.shape[3] + 1))\n        return list(np.unique(self._atlas_data[self._atlas_data != self.background_label]).astype(int))\n\n    def _load_atlas_lut(self, lut: pd.DataFrame | str | Path) -&gt; pd.DataFrame:\n        \"\"\"\n        Load atlas lookup table and make sure it contains required columns\n\n        Parameters\n        ----------\n        lut : pd.DataFrame | str | Path\n            Lookup table to load.\n\n        Returns\n        -------\n        pd.DataFrame\n            Loaded lookup table.\n\n        Raises\n        ------\n        ValueError\n            If required columns are missing.\n        \"\"\"\n        lut_df = lut if isinstance(lut, pd.DataFrame) else pd.read_csv(lut, sep=\"\\t\")\n        required_columns = self.REQUIRED_LUT_COLUMNS\n        if not required_columns.issubset(lut_df.columns):\n            missing = required_columns - set(lut_df.columns)\n            raise MissingLUTColumnsError(missing)\n\n        return lut_df\n\n    @property\n    def regions(self) -&gt; tuple[int, ...]:\n        \"\"\"Tuple of regions defined in the atlas.\"\"\"\n        return self._regions\n\n    def _apply_mask_to_atlas(self) -&gt; nib.Nifti1Image:\n        \"\"\"\n        Apply masking to parcellation atlas.\n\n        Returns\n        -------\n        nib.Nifti1Image\n            Masked atlas image.\n        \"\"\"\n        atlas_data = np.asarray(self._prepared_atlas_img.get_fdata())\n        mask_data = np.asarray(self._prepared_mask.get_fdata()) &gt; self.mask_threshold\n        if atlas_data.ndim == 4:\n            atlas_data[~mask_data] = 0.0\n        else:\n            atlas_data[~mask_data] = self.background_label\n        return nib.Nifti1Image(atlas_data, self._prepared_atlas_img.affine, self._prepared_atlas_img.header)\n\n    def _prepare_map(\n        self,\n        source: nib.Nifti1Image,\n        reference: nib.Nifti1Image,\n        interpolation: str = \"nearest\",\n    ) -&gt; nib.Nifti1Image:\n        \"\"\"Resample source image to reference image grid if needed.\n\n        Parameters\n        ----------\n        source : nib.Nifti1Image\n            Source image to resample.\n        reference : nib.Nifti1Image\n            Reference image defining the target grid.\n\n        Returns\n        -------\n        nib.Nifti1Image\n            Resampled image.\n        \"\"\"\n        return resample_to_img(\n            source,\n            reference,\n            interpolation=interpolation,\n            force_resample=True,\n            copy_header=True,\n        )\n\n    def _build_regions(self, labels: Mapping[int, str] | Sequence[str] | None) -&gt; tuple[int, ...]:\n        \"\"\"\n        Build region definitions from atlas data and optional labels.\n\n        Parameters\n        ----------\n        labels : Mapping[int, str] | Sequence[str] | None\n            Optional labels provided by the user.\n        \"\"\"\n        atlas_ids = set(self._get_labels(labels))\n        if not self._is_probabilistic:\n            atlas_ids.discard(self.background_label)\n        return tuple(sorted(atlas_ids))\n\n    def _load_atlas_data(self) -&gt; np.ndarray:\n        atlas_data = np.asarray(self.atlas_img.get_fdata())\n        if atlas_data.ndim == 3:\n            return atlas_data.astype(int)\n        elif atlas_data.ndim == 4:\n            return atlas_data.astype(np.float32)\n        raise AtlasShapeError(ndim=atlas_data.ndim)\n\n    def _prepare_stat_functions(\n        self,\n        stat_functions: Mapping[str, Callable[..., float]] | None = None,\n        *,\n        fallback: Mapping[str, Callable[..., float]] | None = None,\n        stat_tier: str | None = None,\n    ) -&gt; list[Statistic]:\n        \"\"\"\n        Generate a list of summary statistics to describe each ROI.\n\n        Parameters\n        ----------\n        stat_functions : Mapping[str, Callable[..., float]] | None\n            Either a mapping of statistic names to functions or None to use defaults.\n            When provided, takes precedence over ``stat_tier``.\n        fallback : Mapping[str, Callable[..., float]] | None, optional\n            Fallback statistics to use if stat_functions is None, by default None.\n            Ignored when ``stat_tier`` is set.\n        stat_tier : str | None, optional\n            Named tier to select when ``stat_functions`` is ``None``.\n            Valid values: ``\"core\"``, ``\"extended\"``, ``\"diagnostic\"``, ``\"all\"``.\n\n        Returns\n        -------\n        list[Statistic]\n            List of prepared statistics.\n\n        Raises\n        ------\n        ValueError\n            If no statistical functions are provided, or if an unknown tier name\n            is supplied.\n        \"\"\"\n        if stat_functions is None:\n            if stat_tier is not None:\n                if stat_tier not in STATISTIC_TIERS:\n                    valid = \", \".join(f'\"{k}\"' for k in STATISTIC_TIERS)\n                    raise MissingStatisticalFunctionError(\n                        message=f\"Unknown stat_tier {stat_tier!r}. Valid tiers: {valid}.\"\n                    )\n                return STATISTIC_TIERS[stat_tier]\n            if fallback is None:\n                return BUILTIN_STATISTICS\n            return fallback\n        if isinstance(stat_functions, Mapping):\n            prepared = [Statistic(name, func) for name, func in stat_functions.items()]\n        elif isinstance(stat_functions, Sequence):\n            if all(isinstance(s, Statistic) for s in stat_functions):\n                prepared = list(stat_functions)\n            else:\n                raise MissingStatisticalFunctionError(message=\"Statistic sequence must contain Statistic instances.\")\n        else:\n            raise MissingStatisticalFunctionError(\n                message=f\"stat_functions must be a Mapping or Sequence, got {type(stat_functions).__name__}\"\n            )\n\n        if not prepared or len(prepared) == 0:\n            raise MissingStatisticalFunctionError()\n        return prepared\n\n    def fit(self, scalar_img: nib.Nifti1Image | str | Path) -&gt; None:\n        \"\"\"\n        Fit the parcellator to a scalar image.\n\n        Parameters\n        ----------\n        scalar_img : nib.Nifti1Image | str | Path\n            Scalar image to fit to.\n        \"\"\"\n        self.scalar_img = _load_nifti(scalar_img)\n        if self.resampling_target in (\"labels\", \"atlas\"):\n            ref_img = self.atlas_img\n            interpolation = \"continuous\"\n        else:\n            ref_img = self.scalar_img\n            interpolation = \"nearest\"\n\n        # Cache atlas resampling by reference image identity (optimization 4.2)\n        ref_id = id(ref_img)\n        if not hasattr(self, \"_cached_atlas_ref_id\") or self._cached_atlas_ref_id != ref_id:\n            atlas_interpolation = \"continuous\" if self._is_probabilistic else \"nearest\"\n            self._prepared_atlas_img = self._prepare_map(self.atlas_img, ref_img, interpolation=atlas_interpolation)\n            self._cached_atlas_ref_id = ref_id\n            # Reset mask cache when atlas cache is invalidated\n            if hasattr(self, \"_cached_mask_ref_id\"):\n                delattr(self, \"_cached_mask_ref_id\")\n\n        self._prepared_scalar_img = self._prepare_map(self.scalar_img, ref_img, interpolation=interpolation)\n\n        # Cache mask resampling by reference image identity (optimization 4.1)\n        if self.mask is not None:\n            if not hasattr(self, \"_cached_mask_ref_id\") or self._cached_mask_ref_id != ref_id:\n                self._prepared_mask = self._prepare_map(self.mask, ref_img, interpolation=\"nearest\")\n                self._cached_mask_ref_id = ref_id\n            self._prepared_atlas_img = self._apply_mask_to_atlas()\n\n        self.ref_img = ref_img\n        if isinstance(scalar_img, (str, Path)):\n            self._fitted_scalar_id = str(scalar_img)\n        else:\n            self._fitted_scalar_id = id(scalar_img)\n\n    def transform(self, scalar_img: str | Path | nib.Nifti1Image) -&gt; pd.DataFrame:\n        \"\"\"\n        Apply the parcellation to the fitted scalar image.\n\n        Returns\n        -------\n        pd.DataFrame\n            DataFrame containing parcellation statistics for each region.\n        \"\"\"\n        if not hasattr(self, \"_prepared_atlas_img\") or not hasattr(self, \"_prepared_scalar_img\"):\n            raise ParcellatorNotFittedError()\n\n        current_scalar_id: str | int = str(scalar_img) if isinstance(scalar_img, (str, Path)) else id(scalar_img)\n\n        if self._fitted_scalar_id == current_scalar_id:\n            prepared_scalar_img = self._prepared_scalar_img\n        else:\n            prepared_scalar_img = self._prepare_map(\n                _load_nifti(scalar_img),\n                self.ref_img,\n                interpolation=\"continuous\",\n            )\n\n        scalar_data = np.asarray(prepared_scalar_img.get_fdata())\n        if self._is_probabilistic:\n            atlas_data = np.asarray(self._prepared_atlas_img.get_fdata())\n        else:\n            atlas_data = np.asarray(self._prepared_atlas_img.get_fdata()).astype(int)\n        if self.lut is not None:\n            result = self.lut.copy()\n        else:\n            result = pd.DataFrame({\"index\": self._regions, \"label\": [str(r) for r in self._regions]})\n\n        valid_region_ids = set(result[\"index\"])\n        stats_data = {}\n\n        for region_id in self._regions:\n            if region_id not in valid_region_ids:\n                logger.warning(\"Region ID %d not found in LUT; skipping.\", region_id)\n                continue\n            if self._is_probabilistic:\n                vol_idx = region_id - 1  # 1-based LUT index \u2192 0-based volume index\n                prob_map = atlas_data[:, :, :, vol_idx]\n                parcel_mask = prob_map &gt; self.atlas_threshold\n            else:\n                parcel_mask = atlas_data == region_id\n            parcel_values = scalar_data[parcel_mask]\n\n            region_stats = {}\n            for stat in self._stat_functions:\n                stat_name = stat.name\n                stat_func = stat.function\n                if stat.requires_image:\n                    stat_value = stat_func(parcel_values, prepared_scalar_img)\n                else:\n                    stat_value = stat_func(parcel_values)\n                region_stats[stat_name] = stat_value\n            stats_data[region_id] = region_stats\n\n        stats_df = pd.DataFrame.from_dict(stats_data, orient=\"index\")\n        stats_df.index.name = \"index\"\n        result = result.merge(stats_df, on=\"index\", how=\"left\")\n\n        return result\n</code></pre>"},{"location":"api/#parcellate.parcellation.volume.VolumetricParcellator.regions","title":"<code>regions</code>  <code>property</code>","text":"<p>Tuple of regions defined in the atlas.</p>"},{"location":"api/#parcellate.parcellation.volume.VolumetricParcellator.__init__","title":"<code>__init__(atlas_img, labels=None, lut=None, *, mask=None, mask_threshold=0.0, atlas_threshold=0.0, background_label=0, resampling_target='data', stat_functions=None, stat_tier=None)</code>","text":"<p>Initialize a volumetric parcellator</p> <p>Parameters:</p> Name Type Description Default <code>atlas_img</code> <code>Nifti1Image | str | Path</code> <p>The atlas image defining the parcellation.</p> required <code>labels</code> <code>Mapping[int, str] | Sequence[str] | None</code> <p>Region labels mapping or sequence, by default None</p> <code>None</code> <code>lut</code> <code>DataFrame | str | Path | None</code> <p>Lookup table for region labels, by default None. Must include columns \"index\" and \"label\" following the BIDS standard.</p> <code>None</code> <code>mask</code> <code>Nifti1Image | str | Path | None</code> <p>Optional mask to apply to the atlas, by default None</p> <code>None</code> <code>mask_threshold</code> <code>float</code> <p>Threshold for the mask image. Voxels with mask values strictly greater than this threshold are included; all others are excluded. Default is <code>0.0</code>, which preserves the original behaviour of including every non-zero voxel. Use values in [0, 1] for probability maps (e.g. <code>0.5</code> to keep only voxels with &gt;50 % gray-matter probability).</p> <code>0.0</code> <code>atlas_threshold</code> <code>float</code> <p>Threshold for probabilistic (4D) atlas volumes. Voxels with probability strictly greater than this value are included in each region's mask. Default is <code>0.0</code> (any non-zero probability voxel is included). Only used when the atlas image is 4D. Ignored for 3D discrete atlases.</p> <code>0.0</code> <code>background_label</code> <code>int</code> <p>Label value to treat as background, by default 0</p> <code>0</code> <code>resampling_target</code> <code>Literal['data', 'labels', None]</code> <p>Resampling target for input maps, by default \"data\"</p> <code>'data'</code> <code>stat_functions</code> <code>Mapping[str, StatFunction] | None</code> <p>Mapping of statistic names to functions, by default None. When provided, takes precedence over <code>stat_tier</code>.</p> <code>None</code> <code>stat_tier</code> <code>str | None</code> <p>Named statistics tier to use when <code>stat_functions</code> is <code>None</code>. Valid values: <code>\"core\"</code>, <code>\"extended\"</code>, <code>\"diagnostic\"</code>, <code>\"all\"</code>. Defaults to <code>None</code>, which selects all built-in statistics (equivalent to <code>\"diagnostic\"</code>).</p> <code>None</code> Source code in <code>src/parcellate/parcellation/volume.py</code> <pre><code>def __init__(\n    self,\n    atlas_img: nib.Nifti1Image | str | Path,\n    labels: Mapping[int, str] | Sequence[str] | None = None,\n    lut: pd.DataFrame | str | Path | None = None,\n    *,\n    mask: nib.Nifti1Image | str | Path | None = None,\n    mask_threshold: float = 0.0,\n    atlas_threshold: float = 0.0,\n    background_label: int = 0,\n    resampling_target: Literal[\"data\", \"labels\", \"atlas\", None] = \"data\",\n    stat_functions: Mapping[str, Callable[..., float]] | None = None,\n    stat_tier: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize a volumetric parcellator\n\n    Parameters\n    ----------\n    atlas_img : nib.Nifti1Image | str | Path\n        The atlas image defining the parcellation.\n    labels : Mapping[int, str] | Sequence[str] | None, optional\n        Region labels mapping or sequence, by default None\n    lut : pd.DataFrame | str | Path | None, optional\n        Lookup table for region labels, by default None. Must include columns\n        \"index\" and \"label\" following the BIDS standard.\n    mask : nib.Nifti1Image | str | Path | None, optional\n        Optional mask to apply to the atlas, by default None\n    mask_threshold : float, optional\n        Threshold for the mask image. Voxels with mask values strictly greater\n        than this threshold are included; all others are excluded. Default is\n        ``0.0``, which preserves the original behaviour of including every\n        non-zero voxel. Use values in [0, 1] for probability maps (e.g.\n        ``0.5`` to keep only voxels with &gt;50 % gray-matter probability).\n    atlas_threshold : float, optional\n        Threshold for probabilistic (4D) atlas volumes. Voxels with probability\n        strictly greater than this value are included in each region's mask.\n        Default is ``0.0`` (any non-zero probability voxel is included). Only\n        used when the atlas image is 4D. Ignored for 3D discrete atlases.\n    background_label : int, optional\n        Label value to treat as background, by default 0\n    resampling_target : Literal[\"data\", \"labels\", None], optional\n        Resampling target for input maps, by default \"data\"\n    stat_functions : Mapping[str, StatFunction] | None, optional\n        Mapping of statistic names to functions, by default None.\n        When provided, takes precedence over ``stat_tier``.\n    stat_tier : str | None, optional\n        Named statistics tier to use when ``stat_functions`` is ``None``.\n        Valid values: ``\"core\"``, ``\"extended\"``, ``\"diagnostic\"``, ``\"all\"``.\n        Defaults to ``None``, which selects all built-in statistics\n        (equivalent to ``\"diagnostic\"``).\n    \"\"\"\n    self.atlas_img = _load_nifti(atlas_img)\n    self.lut = self._load_atlas_lut(lut) if lut is not None else None\n    self.mask_threshold = float(mask_threshold)\n    self.atlas_threshold = float(atlas_threshold)\n    self.mask = self._load_mask(mask) if mask is not None else None\n    self.background_label = int(background_label)\n    self.resampling_target = resampling_target\n    self._atlas_data = self._load_atlas_data()\n    self._is_probabilistic = self._atlas_data.ndim == 4\n    self._regions = self._build_regions(labels)\n    self._stat_functions = self._prepare_stat_functions(stat_functions, stat_tier=stat_tier)\n    self._fitted_scalar_id: str | int | None = None\n</code></pre>"},{"location":"api/#parcellate.parcellation.volume.VolumetricParcellator.fit","title":"<code>fit(scalar_img)</code>","text":"<p>Fit the parcellator to a scalar image.</p> <p>Parameters:</p> Name Type Description Default <code>scalar_img</code> <code>Nifti1Image | str | Path</code> <p>Scalar image to fit to.</p> required Source code in <code>src/parcellate/parcellation/volume.py</code> <pre><code>def fit(self, scalar_img: nib.Nifti1Image | str | Path) -&gt; None:\n    \"\"\"\n    Fit the parcellator to a scalar image.\n\n    Parameters\n    ----------\n    scalar_img : nib.Nifti1Image | str | Path\n        Scalar image to fit to.\n    \"\"\"\n    self.scalar_img = _load_nifti(scalar_img)\n    if self.resampling_target in (\"labels\", \"atlas\"):\n        ref_img = self.atlas_img\n        interpolation = \"continuous\"\n    else:\n        ref_img = self.scalar_img\n        interpolation = \"nearest\"\n\n    # Cache atlas resampling by reference image identity (optimization 4.2)\n    ref_id = id(ref_img)\n    if not hasattr(self, \"_cached_atlas_ref_id\") or self._cached_atlas_ref_id != ref_id:\n        atlas_interpolation = \"continuous\" if self._is_probabilistic else \"nearest\"\n        self._prepared_atlas_img = self._prepare_map(self.atlas_img, ref_img, interpolation=atlas_interpolation)\n        self._cached_atlas_ref_id = ref_id\n        # Reset mask cache when atlas cache is invalidated\n        if hasattr(self, \"_cached_mask_ref_id\"):\n            delattr(self, \"_cached_mask_ref_id\")\n\n    self._prepared_scalar_img = self._prepare_map(self.scalar_img, ref_img, interpolation=interpolation)\n\n    # Cache mask resampling by reference image identity (optimization 4.1)\n    if self.mask is not None:\n        if not hasattr(self, \"_cached_mask_ref_id\") or self._cached_mask_ref_id != ref_id:\n            self._prepared_mask = self._prepare_map(self.mask, ref_img, interpolation=\"nearest\")\n            self._cached_mask_ref_id = ref_id\n        self._prepared_atlas_img = self._apply_mask_to_atlas()\n\n    self.ref_img = ref_img\n    if isinstance(scalar_img, (str, Path)):\n        self._fitted_scalar_id = str(scalar_img)\n    else:\n        self._fitted_scalar_id = id(scalar_img)\n</code></pre>"},{"location":"api/#parcellate.parcellation.volume.VolumetricParcellator.transform","title":"<code>transform(scalar_img)</code>","text":"<p>Apply the parcellation to the fitted scalar image.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing parcellation statistics for each region.</p> Source code in <code>src/parcellate/parcellation/volume.py</code> <pre><code>def transform(self, scalar_img: str | Path | nib.Nifti1Image) -&gt; pd.DataFrame:\n    \"\"\"\n    Apply the parcellation to the fitted scalar image.\n\n    Returns\n    -------\n    pd.DataFrame\n        DataFrame containing parcellation statistics for each region.\n    \"\"\"\n    if not hasattr(self, \"_prepared_atlas_img\") or not hasattr(self, \"_prepared_scalar_img\"):\n        raise ParcellatorNotFittedError()\n\n    current_scalar_id: str | int = str(scalar_img) if isinstance(scalar_img, (str, Path)) else id(scalar_img)\n\n    if self._fitted_scalar_id == current_scalar_id:\n        prepared_scalar_img = self._prepared_scalar_img\n    else:\n        prepared_scalar_img = self._prepare_map(\n            _load_nifti(scalar_img),\n            self.ref_img,\n            interpolation=\"continuous\",\n        )\n\n    scalar_data = np.asarray(prepared_scalar_img.get_fdata())\n    if self._is_probabilistic:\n        atlas_data = np.asarray(self._prepared_atlas_img.get_fdata())\n    else:\n        atlas_data = np.asarray(self._prepared_atlas_img.get_fdata()).astype(int)\n    if self.lut is not None:\n        result = self.lut.copy()\n    else:\n        result = pd.DataFrame({\"index\": self._regions, \"label\": [str(r) for r in self._regions]})\n\n    valid_region_ids = set(result[\"index\"])\n    stats_data = {}\n\n    for region_id in self._regions:\n        if region_id not in valid_region_ids:\n            logger.warning(\"Region ID %d not found in LUT; skipping.\", region_id)\n            continue\n        if self._is_probabilistic:\n            vol_idx = region_id - 1  # 1-based LUT index \u2192 0-based volume index\n            prob_map = atlas_data[:, :, :, vol_idx]\n            parcel_mask = prob_map &gt; self.atlas_threshold\n        else:\n            parcel_mask = atlas_data == region_id\n        parcel_values = scalar_data[parcel_mask]\n\n        region_stats = {}\n        for stat in self._stat_functions:\n            stat_name = stat.name\n            stat_func = stat.function\n            if stat.requires_image:\n                stat_value = stat_func(parcel_values, prepared_scalar_img)\n            else:\n                stat_value = stat_func(parcel_values)\n            region_stats[stat_name] = stat_value\n        stats_data[region_id] = region_stats\n\n    stats_df = pd.DataFrame.from_dict(stats_data, orient=\"index\")\n    stats_df.index.name = \"index\"\n    result = result.merge(stats_df, on=\"index\", how=\"left\")\n\n    return result\n</code></pre>"},{"location":"api/#metrics","title":"Metrics","text":""},{"location":"api/#parcellate.metrics.base","title":"<code>base</code>","text":""},{"location":"api/#parcellate.metrics.base.Statistic","title":"<code>Statistic</code>  <code>dataclass</code>","text":"<p>Container for a parcellation statistic.</p> Source code in <code>src/parcellate/metrics/base.py</code> <pre><code>@dataclass\nclass Statistic:\n    \"\"\"Container for a parcellation statistic.\"\"\"\n\n    name: str\n    function: Callable[..., Any]\n    requires_image: bool = False\n</code></pre>"},{"location":"api/#parcellate.metrics.volume","title":"<code>volume</code>","text":"<p>A battery of volumetric parcellation statistics.</p>"},{"location":"api/#parcellate.metrics.volume.volume","title":"<code>volume(parcel_values, scalar_img)</code>","text":"<p>Compute the actual tissue volume within a mask using modulated images.</p> <p>Parameters:</p> Name Type Description Default <code>parcel_values</code> <code>ndarray</code> <p>The modulated tissue segment values within the ROI.</p> required <code>scalar_img</code> <code>Nifti1Image</code> <p>The modulated tissue segment (e.g., mwp1.nii).</p> required Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def volume(parcel_values: np.ndarray, scalar_img: nib.Nifti1Image) -&gt; float:\n    \"\"\"Compute the actual tissue volume within a mask using modulated images.\n\n    Parameters\n    ----------\n    parcel_values : np.ndarray\n        The modulated tissue segment values within the ROI.\n    scalar_img : nib.Nifti1Image\n        The modulated tissue segment (e.g., mwp1.nii).\n    \"\"\"\n    # Calculate the volume of a single voxel in mm^3\n    voxel_sizes = scalar_img.header.get_zooms()[:3]\n    voxel_volume = np.prod(voxel_sizes)\n\n    # Correct step: Sum the intensities within the mask\n    # This represents the sum of tissue fractions/volume units\n    tissue_sum = np.nansum(parcel_values)\n\n    # Total volume in mm^3\n    total_volume = tissue_sum * voxel_volume\n\n    return float(total_volume)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.voxel_count","title":"<code>voxel_count(parcel_values)</code>","text":"<p>Compute the count of non-zero voxels in a parcel.</p> <p>This function counts the number of voxels in a parcel that have non-zero and non-NaN values. This is useful for modulated tissue maps (e.g., CAT12's mwp* files) where zero values indicate no tissue present.</p> <p>Parameters:</p> Name Type Description Default <code>parcel_values</code> <code>ndarray</code> <p>An array of scalar values for voxels within the parcel.</p> required <p>Returns:</p> Type Description <code>int</code> <p>The number of non-zero, non-NaN voxels in the parcel.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def voxel_count(parcel_values: np.ndarray) -&gt; int:\n    \"\"\"Compute the count of non-zero voxels in a parcel.\n\n    This function counts the number of voxels in a parcel that have\n    non-zero and non-NaN values. This is useful for modulated tissue\n    maps (e.g., CAT12's mwp* files) where zero values indicate no\n    tissue present.\n\n    Parameters\n    ----------\n    parcel_values : np.ndarray\n        An array of scalar values for voxels within the parcel.\n\n    Returns\n    -------\n    int\n        The number of non-zero, non-NaN voxels in the parcel.\n    \"\"\"\n    num_voxels = np.sum(parcel_values.astype(bool))\n    return int(num_voxels)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.z_filtered_mean","title":"<code>z_filtered_mean(values, z_thresh=3.0)</code>","text":"<p>Compute the mean of values after applying a z-score filter.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to filter and compute the mean from.</p> required <code>z_thresh</code> <code>float</code> <p>The z-score threshold for filtering, by default 3.0.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The mean of the filtered values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def z_filtered_mean(values: np.ndarray, z_thresh: float = 3.0) -&gt; float:\n    \"\"\"Compute the mean of values after applying a z-score filter.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to filter and compute the mean from.\n    z_thresh : float, optional\n        The z-score threshold for filtering, by default 3.0.\n\n    Returns\n    -------\n    float\n        The mean of the filtered values.\n    \"\"\"\n    filtered = _z_score_filter(values, z_thresh)\n    if filtered.size == 0:\n        return float(np.nanmean(values))\n    return float(np.nanmean(filtered))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.z_filtered_std","title":"<code>z_filtered_std(values, z_thresh=3.0)</code>","text":"<p>Compute the standard deviation of values after applying a z-score filter.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to filter and compute the standard deviation from.</p> required <code>z_thresh</code> <code>float</code> <p>The z-score threshold for filtering, by default 3.0.</p> <code>3.0</code> <p>Returns:</p> Type Description <code>float</code> <p>The standard deviation of the filtered values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def z_filtered_std(values: np.ndarray, z_thresh: float = 3.0) -&gt; float:\n    \"\"\"Compute the standard deviation of values after applying a z-score filter.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to filter and compute the standard deviation from.\n    z_thresh : float, optional\n        The z-score threshold for filtering, by default 3.0.\n\n    Returns\n    -------\n    float\n        The standard deviation of the filtered values.\n    \"\"\"\n    # If std is 0, all values are identical, so filtered std is also 0\n    if np.nanstd(values) == 0:\n        return 0.0\n    filtered = _z_score_filter(values, z_thresh)\n    if filtered.size == 0:\n        return float(np.nanstd(values))\n    return float(np.nanstd(filtered))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.iqr_filtered_mean","title":"<code>iqr_filtered_mean(values, factor=1.5)</code>","text":"<p>Compute the mean of values after applying an interquartile range (IQR) filter.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to filter and compute the mean from.</p> required <code>factor</code> <code>float</code> <p>The IQR factor for filtering, by default 1.5.</p> <code>1.5</code> <p>Returns:</p> Type Description <code>float</code> <p>The mean of the filtered values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def iqr_filtered_mean(values: np.ndarray, factor: float = 1.5) -&gt; float:\n    \"\"\"Compute the mean of values after applying an interquartile range (IQR) filter.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to filter and compute the mean from.\n    factor : float, optional\n        The IQR factor for filtering, by default 1.5.\n\n    Returns\n    -------\n    float\n        The mean of the filtered values.\n    \"\"\"\n    filtered = _iqr_filter(values, factor)\n    if filtered.size == 0:\n        return float(np.nanmean(values))\n    return float(np.nanmean(filtered))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.iqr_filtered_std","title":"<code>iqr_filtered_std(values, factor=1.5)</code>","text":"<p>Compute the standard deviation of values after applying an interquartile range (IQR) filter.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to filter and compute the standard deviation from.</p> required <code>factor</code> <code>float</code> <p>The IQR factor for filtering, by default 1.5.</p> <code>1.5</code> <p>Returns:</p> Type Description <code>float</code> <p>The standard deviation of the filtered values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def iqr_filtered_std(values: np.ndarray, factor: float = 1.5) -&gt; float:\n    \"\"\"Compute the standard deviation of values after applying an interquartile range (IQR) filter.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to filter and compute the standard deviation from.\n    factor : float, optional\n        The IQR factor for filtering, by default 1.5.\n\n    Returns\n    -------\n    float\n        The standard deviation of the filtered values.\n    \"\"\"\n    filtered = _iqr_filter(values, factor)\n    if filtered.size == 0:\n        return float(np.nanstd(values))\n    return float(np.nanstd(filtered))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.robust_mean","title":"<code>robust_mean(values)</code>","text":"<p>Compute the robust mean of values using median and MAD.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to compute the robust mean from.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The robust mean of the values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def robust_mean(values: np.ndarray) -&gt; float:\n    \"\"\"Compute the robust mean of values using median and MAD.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to compute the robust mean from.\n\n    Returns\n    -------\n    float\n        The robust mean of the values.\n    \"\"\"\n    filtered = _robust_filter(values)\n    if filtered.size == 0:\n        return float(np.nanmedian(values))\n    return float(np.nanmean(filtered))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.robust_std","title":"<code>robust_std(values)</code>","text":"<p>Compute the robust standard deviation of values using median and MAD.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to compute the robust standard deviation from.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The robust standard deviation of the values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def robust_std(values: np.ndarray) -&gt; float:\n    \"\"\"Compute the robust standard deviation of values using median and MAD.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to compute the robust standard deviation from.\n\n    Returns\n    -------\n    float\n        The robust standard deviation of the values.\n    \"\"\"\n    filtered = _robust_filter(values)\n    if filtered.size == 0:\n        return float(np.nanstd(values))\n    return float(np.nanstd(filtered))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.mad_median","title":"<code>mad_median(values)</code>","text":"<p>Compute the median absolute deviation (MAD) of values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to compute the MAD from.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The MAD of the values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def mad_median(values: np.ndarray) -&gt; float:\n    \"\"\"Compute the median absolute deviation (MAD) of values.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to compute the MAD from.\n\n    Returns\n    -------\n    float\n        The MAD of the values.\n    \"\"\"\n    median_val = np.nanmedian(values)\n    mad = np.nanmedian(np.abs(values - median_val))\n    return float(mad)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.volsum","title":"<code>volsum(values)</code>","text":"<p>Compute the sum of values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>ndarray</code> <p>The array of values to compute the sum from.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The sum of the values.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def volsum(values: np.ndarray) -&gt; float:\n    \"\"\"Compute the sum of values.\n\n    Parameters\n    ----------\n    values : np.ndarray\n        The array of values to compute the sum from.\n\n    Returns\n    -------\n    float\n        The sum of the values.\n    \"\"\"\n    return float(np.nansum(values))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.cv","title":"<code>cv(values)</code>","text":"<p>Classical coefficient of variation (CV = SD / mean).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Coefficient of variation. Higher values indicate more relative variability.</p> Notes <p>Sensitive to mean approaching zero. For metrics that can be zero or negative, consider using robust_cv instead.</p> <p>Typical values for neuroimaging: - Cortical thickness: CV ~ 0.10 - FA: CV ~ 0.15 - MD: CV ~ 0.20</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def cv(values):\n    \"\"\"\n    Classical coefficient of variation (CV = SD / mean).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Coefficient of variation. Higher values indicate more relative variability.\n\n    Notes\n    -----\n    Sensitive to mean approaching zero. For metrics that can be zero or negative,\n    consider using robust_cv instead.\n\n    Typical values for neuroimaging:\n    - Cortical thickness: CV ~ 0.10\n    - FA: CV ~ 0.15\n    - MD: CV ~ 0.20\n    \"\"\"\n    return np.std(values) / (np.mean(values) + 1e-10)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.robust_cv","title":"<code>robust_cv(values)</code>","text":"<p>Robust coefficient of variation (IQR / median).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Robust coefficient of variation. Less sensitive to outliers than classical CV.</p> Notes <p>Recommended when outliers are present or suspected. More stable than classical CV for distributions with heavy tails.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def robust_cv(values):\n    \"\"\"\n    Robust coefficient of variation (IQR / median).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Robust coefficient of variation. Less sensitive to outliers than classical CV.\n\n    Notes\n    -----\n    Recommended when outliers are present or suspected. More stable than classical\n    CV for distributions with heavy tails.\n    \"\"\"\n    return iqr(values) / (np.median(values) + 1e-10)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.quartile_dispersion","title":"<code>quartile_dispersion(values)</code>","text":"<p>Quartile coefficient of dispersion.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Quartile dispersion coefficient: (Q3 - Q1) / (Q3 + Q1)</p> Notes <p>Scale-free measure of dispersion. Bounded between 0 and 1. Less affected by extreme values than CV.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def quartile_dispersion(values):\n    \"\"\"\n    Quartile coefficient of dispersion.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Quartile dispersion coefficient: (Q3 - Q1) / (Q3 + Q1)\n\n    Notes\n    -----\n    Scale-free measure of dispersion. Bounded between 0 and 1.\n    Less affected by extreme values than CV.\n    \"\"\"\n    clean = np.asarray(values)\n    clean = clean[np.isfinite(clean)]\n    if len(clean) == 0:\n        return float(\"nan\")\n    q1, q3 = np.percentile(clean, [25, 75])\n    return (q3 - q1) / (q3 + q1 + 1e-10)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.skewness","title":"<code>skewness(values)</code>","text":"<p>Skewness (third standardized moment).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Skewness value. 0 = symmetric, &gt;0 = right tail, &lt;0 = left tail.</p> Notes <p>Problematic if |skewness| &gt; 0.5.</p> <p>Neuroimaging context: - Cortical thickness often shows negative skew (-0.2 to -0.8) due to   partial volume effects - FA often shows positive skew (0.3 to 1.2) due to crossing fibers</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def skewness(values):\n    \"\"\"\n    Skewness (third standardized moment).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Skewness value. 0 = symmetric, &gt;0 = right tail, &lt;0 = left tail.\n\n    Notes\n    -----\n    Problematic if |skewness| &gt; 0.5.\n\n    Neuroimaging context:\n    - Cortical thickness often shows negative skew (-0.2 to -0.8) due to\n      partial volume effects\n    - FA often shows positive skew (0.3 to 1.2) due to crossing fibers\n    \"\"\"\n    return float(skew(values, nan_policy=\"omit\"))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.excess_kurtosis","title":"<code>excess_kurtosis(values)</code>","text":"<p>Excess kurtosis (fourth standardized moment minus 3).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Excess kurtosis. 0 = normal, &gt;0 = heavy tails, &lt;0 = light tails.</p> Notes <p>Problematic if |kurtosis| &gt; 1.0.</p> <p>Positive kurtosis indicates outlier-prone distributions. Common in diffusion metrics due to partial volume effects with CSF.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def excess_kurtosis(values):\n    \"\"\"\n    Excess kurtosis (fourth standardized moment minus 3).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Excess kurtosis. 0 = normal, &gt;0 = heavy tails, &lt;0 = light tails.\n\n    Notes\n    -----\n    Problematic if |kurtosis| &gt; 1.0.\n\n    Positive kurtosis indicates outlier-prone distributions. Common in diffusion\n    metrics due to partial volume effects with CSF.\n    \"\"\"\n    return float(scipy_kurtosis(values, nan_policy=\"omit\"))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.abs_skewness","title":"<code>abs_skewness(values)</code>","text":"<p>Absolute value of skewness.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Absolute skewness. Useful for categorizing without caring about direction.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def abs_skewness(values):\n    \"\"\"\n    Absolute value of skewness.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Absolute skewness. Useful for categorizing without caring about direction.\n    \"\"\"\n    return float(np.abs(skew(values, nan_policy=\"omit\")))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.abs_excess_kurtosis","title":"<code>abs_excess_kurtosis(values)</code>","text":"<p>Absolute value of excess kurtosis.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Absolute excess kurtosis.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def abs_excess_kurtosis(values):\n    \"\"\"\n    Absolute value of excess kurtosis.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Absolute excess kurtosis.\n    \"\"\"\n    return float(np.abs(scipy_kurtosis(values, nan_policy=\"omit\")))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.bimodality_coefficient","title":"<code>bimodality_coefficient(values)</code>","text":"<p>Bimodality coefficient (Pfister et al. 2013).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Bimodality coefficient. Values &gt; 0.555 suggest bimodal/multimodal distribution.</p> Notes <p>Calculated as: BC = (skew\u00b2 + 1) / (kurtosis + 3(n-1)\u00b2/((n-2)(n-3)))</p> <p>Critical for cortical thickness ROIs that span gyri and sulci, which often show bimodal distributions.</p> References <p>Pfister R, Schwarz KA, Janczyk M, Dale R, Freeman JB (2013). Good things peak in pairs: a note on the bimodality coefficient. Front Psychol 4:700.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def bimodality_coefficient(values):\n    \"\"\"\n    Bimodality coefficient (Pfister et al. 2013).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Bimodality coefficient. Values &gt; 0.555 suggest bimodal/multimodal distribution.\n\n    Notes\n    -----\n    Calculated as: BC = (skew\u00b2 + 1) / (kurtosis + 3(n-1)\u00b2/((n-2)(n-3)))\n\n    Critical for cortical thickness ROIs that span gyri and sulci, which often\n    show bimodal distributions.\n\n    References\n    ----------\n    Pfister R, Schwarz KA, Janczyk M, Dale R, Freeman JB (2013).\n    Good things peak in pairs: a note on the bimodality coefficient.\n    Front Psychol 4:700.\n    \"\"\"\n    n = len(values)\n    if n &lt; 4:\n        return np.nan\n\n    skew_val = skew(values, nan_policy=\"omit\")\n    kurt_val = scipy_kurtosis(values, nan_policy=\"omit\")\n\n    m3_squared = skew_val**2\n    m4 = kurt_val + 3  # Convert excess kurtosis to raw kurtosis\n\n    bc = (m3_squared + 1) / (m4 + 3 * ((n - 1) ** 2) / ((n - 2) * (n - 3)))\n    return float(bc)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.prop_outliers_2sd","title":"<code>prop_outliers_2sd(values)</code>","text":"<p>Proportion of values beyond \u00b12 standard deviations from mean.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Proportion of outliers (0 to 1). Expected ~0.046 for normal distribution.</p> Notes <p>Problematic if &gt; 0.10 (10%).</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def prop_outliers_2sd(values):\n    \"\"\"\n    Proportion of values beyond \u00b12 standard deviations from mean.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Proportion of outliers (0 to 1). Expected ~0.046 for normal distribution.\n\n    Notes\n    -----\n    Problematic if &gt; 0.10 (10%).\n    \"\"\"\n    mean, std = np.mean(values), np.std(values)\n    return np.mean(np.abs(values - mean) &gt; 2 * std)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.prop_outliers_3sd","title":"<code>prop_outliers_3sd(values)</code>","text":"<p>Proportion of values beyond \u00b13 standard deviations from mean.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Proportion of outliers (0 to 1). Expected ~0.003 for normal distribution.</p> Notes <p>Problematic if &gt; 0.02 (2%). High values suggest segmentation errors or image quality issues.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def prop_outliers_3sd(values):\n    \"\"\"\n    Proportion of values beyond \u00b13 standard deviations from mean.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Proportion of outliers (0 to 1). Expected ~0.003 for normal distribution.\n\n    Notes\n    -----\n    Problematic if &gt; 0.02 (2%).\n    High values suggest segmentation errors or image quality issues.\n    \"\"\"\n    mean, std = np.mean(values), np.std(values)\n    return np.mean(np.abs(values - mean) &gt; 3 * std)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.prop_outliers_iqr","title":"<code>prop_outliers_iqr(values)</code>","text":"<p>Proportion of Tukey fence outliers (beyond Q1 - 1.5IQR or Q3 + 1.5IQR).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Proportion of outliers (0 to 1). Expected ~0.007 for normal distribution.</p> Notes <p>More robust than SD-based outlier detection. This is the standard boxplot definition of outliers. Problematic if &gt; 0.05 (5%).</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def prop_outliers_iqr(values):\n    \"\"\"\n    Proportion of Tukey fence outliers (beyond Q1 - 1.5*IQR or Q3 + 1.5*IQR).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Proportion of outliers (0 to 1). Expected ~0.007 for normal distribution.\n\n    Notes\n    -----\n    More robust than SD-based outlier detection. This is the standard boxplot\n    definition of outliers. Problematic if &gt; 0.05 (5%).\n    \"\"\"\n    clean = np.asarray(values)\n    clean = clean[np.isfinite(clean)]\n    if len(clean) == 0:\n        return float(\"nan\")\n    q1, q3 = np.percentile(clean, [25, 75])\n    iqr_val = q3 - q1\n    lower_fence = q1 - 1.5 * iqr_val\n    upper_fence = q3 + 1.5 * iqr_val\n    return float(np.mean((clean &lt; lower_fence) | (clean &gt; upper_fence)))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.left_tail_mass","title":"<code>left_tail_mass(values)</code>","text":"<p>Proportion of values in left tail (below mean - 2*SD).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Left tail mass. Expected ~0.023 for normal distribution.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def left_tail_mass(values):\n    \"\"\"\n    Proportion of values in left tail (below mean - 2*SD).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Left tail mass. Expected ~0.023 for normal distribution.\n    \"\"\"\n    mean, std = np.mean(values), np.std(values)\n    return np.mean(values &lt; (mean - 2 * std))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.right_tail_mass","title":"<code>right_tail_mass(values)</code>","text":"<p>Proportion of values in right tail (above mean + 2*SD).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Right tail mass. Expected ~0.023 for normal distribution.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def right_tail_mass(values):\n    \"\"\"\n    Proportion of values in right tail (above mean + 2*SD).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Right tail mass. Expected ~0.023 for normal distribution.\n    \"\"\"\n    mean, std = np.mean(values), np.std(values)\n    return np.mean(values &gt; (mean + 2 * std))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.tail_asymmetry","title":"<code>tail_asymmetry(values)</code>","text":"<p>Difference between right and left tail masses.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Tail asymmetry. &gt;0 = heavier right tail, &lt;0 = heavier left tail.</p> Notes <p>Expected ~0 for symmetric distributions. Problematic if |asymmetry| &gt; 0.02. Helps identify which tail is causing distributional problems.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def tail_asymmetry(values):\n    \"\"\"\n    Difference between right and left tail masses.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Tail asymmetry. &gt;0 = heavier right tail, &lt;0 = heavier left tail.\n\n    Notes\n    -----\n    Expected ~0 for symmetric distributions. Problematic if |asymmetry| &gt; 0.02.\n    Helps identify which tail is causing distributional problems.\n    \"\"\"\n    return right_tail_mass(values) - left_tail_mass(values)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.excess_tail_mass","title":"<code>excess_tail_mass(values)</code>","text":"<p>Total excess tail mass beyond what's expected for normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>Excess tail mass. &gt;0 indicates heavy tails.</p> Notes <p>For normal distribution, total tail mass (beyond \u00b12SD) = 4.6%. Excess tail mass = observed - expected. Problematic if &gt; 0.02 (2% excess).</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def excess_tail_mass(values):\n    \"\"\"\n    Total excess tail mass beyond what's expected for normal distribution.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        Excess tail mass. &gt;0 indicates heavy tails.\n\n    Notes\n    -----\n    For normal distribution, total tail mass (beyond \u00b12SD) = 4.6%.\n    Excess tail mass = observed - expected.\n    Problematic if &gt; 0.02 (2% excess).\n    \"\"\"\n    normal_tail_mass = 0.023  # Each tail\n    total_observed = left_tail_mass(values) + right_tail_mass(values)\n    return total_observed - 2 * normal_tail_mass\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.dagostino_k2","title":"<code>dagostino_k2(values)</code>","text":"<p>D'Agostino-Pearson K\u00b2 statistic for normality test.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values (requires n \u2265 20)</p> required <p>Returns:</p> Type Description <code>float</code> <p>K\u00b2 test statistic (chi-squared distributed with 2 df)</p> Notes <p>Returns NaN if n &lt; 20. Higher values indicate stronger deviation from normality.</p> See also <p>dagostino_p : Corresponding p-value</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def dagostino_k2(values):\n    \"\"\"\n    D'Agostino-Pearson K\u00b2 statistic for normality test.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values (requires n \u2265 20)\n\n    Returns\n    -------\n    float\n        K\u00b2 test statistic (chi-squared distributed with 2 df)\n\n    Notes\n    -----\n    Returns NaN if n &lt; 20. Higher values indicate stronger deviation from normality.\n\n    See also\n    --------\n    dagostino_p : Corresponding p-value\n    \"\"\"\n    if len(values) &lt; 20:\n        return np.nan\n    k_stat, _ = normaltest(values)\n    return k_stat\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.dagostino_p","title":"<code>dagostino_p(values)</code>","text":"<p>D'Agostino-Pearson p-value for normality test.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values (requires n \u2265 20)</p> required <p>Returns:</p> Type Description <code>float</code> <p>p-value. Values &lt; 0.05 reject null hypothesis of normality.</p> Notes <p>Returns NaN if n &lt; 20. Combines tests of skewness and kurtosis. More computationally efficient than Shapiro-Wilk for large samples.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def dagostino_p(values):\n    \"\"\"\n    D'Agostino-Pearson p-value for normality test.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values (requires n \u2265 20)\n\n    Returns\n    -------\n    float\n        p-value. Values &lt; 0.05 reject null hypothesis of normality.\n\n    Notes\n    -----\n    Returns NaN if n &lt; 20. Combines tests of skewness and kurtosis.\n    More computationally efficient than Shapiro-Wilk for large samples.\n    \"\"\"\n    if len(values) &lt; 20:\n        return np.nan\n    _, p_val = normaltest(values)\n    return p_val\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.log_dagostino_k2","title":"<code>log_dagostino_k2(values)</code>","text":"<p>Log-transformed D'Agostino K\u00b2 statistic.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values (requires n \u2265 20)</p> required <p>Returns:</p> Type Description <code>float</code> <p>log(K\u00b2). Useful for visualization when K\u00b2 spans many orders of magnitude.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def log_dagostino_k2(values):\n    \"\"\"\n    Log-transformed D'Agostino K\u00b2 statistic.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values (requires n \u2265 20)\n\n    Returns\n    -------\n    float\n        log(K\u00b2). Useful for visualization when K\u00b2 spans many orders of magnitude.\n    \"\"\"\n    k_stat = dagostino_k2(values)\n    if np.isnan(k_stat):\n        return np.nan\n    return np.log(k_stat + 1e-10)\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.shapiro_w","title":"<code>shapiro_w(values)</code>","text":"<p>Shapiro-Wilk W statistic for normality test.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values (requires 3 \u2264 n \u2264 5000)</p> required <p>Returns:</p> Type Description <code>float</code> <p>W statistic (ranges 0 to 1). Values close to 1 indicate normality.</p> Notes <p>Returns NaN if n &lt; 3 or n &gt; 5000 or if test fails. Most powerful normality test but computationally expensive for large samples. Problematic if W &lt; 0.95.</p> See also <p>shapiro_p : Corresponding p-value</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def shapiro_w(values):\n    \"\"\"\n    Shapiro-Wilk W statistic for normality test.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values (requires 3 \u2264 n \u2264 5000)\n\n    Returns\n    -------\n    float\n        W statistic (ranges 0 to 1). Values close to 1 indicate normality.\n\n    Notes\n    -----\n    Returns NaN if n &lt; 3 or n &gt; 5000 or if test fails.\n    Most powerful normality test but computationally expensive for large samples.\n    Problematic if W &lt; 0.95.\n\n    See also\n    --------\n    shapiro_p : Corresponding p-value\n    \"\"\"\n    if not (3 &lt;= len(values) &lt;= 5000):\n        return np.nan\n    try:\n        w_stat, _ = shapiro(values)\n    except Exception:\n        return np.nan\n    else:\n        return w_stat\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.shapiro_p","title":"<code>shapiro_p(values)</code>","text":"<p>Shapiro-Wilk p-value for normality test.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values (requires 3 \u2264 n \u2264 5000)</p> required <p>Returns:</p> Type Description <code>float</code> <p>p-value. Values &lt; 0.05 reject null hypothesis of normality.</p> Notes <p>Returns NaN if n &lt; 3 or n &gt; 5000 or if test fails.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def shapiro_p(values):\n    \"\"\"\n    Shapiro-Wilk p-value for normality test.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values (requires 3 \u2264 n \u2264 5000)\n\n    Returns\n    -------\n    float\n        p-value. Values &lt; 0.05 reject null hypothesis of normality.\n\n    Notes\n    -----\n    Returns NaN if n &lt; 3 or n &gt; 5000 or if test fails.\n    \"\"\"\n    if not (3 &lt;= len(values) &lt;= 5000):\n        return np.nan\n    try:\n        _, p_val = shapiro(values)\n    except Exception:\n        return np.nan\n    else:\n        return p_val\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.qq_correlation","title":"<code>qq_correlation(values)</code>","text":"<p>Correlation coefficient from Q-Q plot (sample vs. theoretical normal quantiles).</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>R value from Q-Q plot (ranges -1 to 1). Values close to 1 indicate normality.</p> Notes <p>Quantifies the linearity of the Q-Q plot. Problematic if R\u00b2 &lt; 0.95.</p> See also <p>qq_r_squared : R\u00b2 version (more commonly reported)</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def qq_correlation(values):\n    \"\"\"\n    Correlation coefficient from Q-Q plot (sample vs. theoretical normal quantiles).\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        R value from Q-Q plot (ranges -1 to 1). Values close to 1 indicate normality.\n\n    Notes\n    -----\n    Quantifies the linearity of the Q-Q plot. Problematic if R\u00b2 &lt; 0.95.\n\n    See also\n    --------\n    qq_r_squared : R\u00b2 version (more commonly reported)\n    \"\"\"\n    (_osm, _osr), (_slope, _intercept, r) = probplot(values, dist=\"norm\", fit=True)\n    return r\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.qq_r_squared","title":"<code>qq_r_squared(values)</code>","text":"<p>R\u00b2 from Q-Q plot regression.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>float</code> <p>R\u00b2 (ranges 0 to 1). Values close to 1 indicate good fit to normal distribution.</p> Notes <p>Problematic if R\u00b2 &lt; 0.95. Single-number summary of Q-Q plot linearity.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def qq_r_squared(values):\n    \"\"\"\n    R\u00b2 from Q-Q plot regression.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    float\n        R\u00b2 (ranges 0 to 1). Values close to 1 indicate good fit to normal distribution.\n\n    Notes\n    -----\n    Problematic if R\u00b2 &lt; 0.95. Single-number summary of Q-Q plot linearity.\n    \"\"\"\n    r = qq_correlation(values)\n    return r**2\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.histogram_entropy","title":"<code>histogram_entropy(values, bins='auto')</code>","text":"<p>Shannon entropy of histogram.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <code>bins</code> <code>int or str</code> <p>Number of histogram bins or binning strategy. Default 'auto'.</p> <code>'auto'</code> <p>Returns:</p> Type Description <code>float</code> <p>Entropy in bits. Higher values indicate more uniform/spread out distributions.</p> Notes <p>Useful for comparing distributional complexity across ROIs. Not directly interpretable for normality assessment.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def histogram_entropy(values, bins=\"auto\"):\n    \"\"\"\n    Shannon entropy of histogram.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n    bins : int or str, optional\n        Number of histogram bins or binning strategy. Default 'auto'.\n\n    Returns\n    -------\n    float\n        Entropy in bits. Higher values indicate more uniform/spread out distributions.\n\n    Notes\n    -----\n    Useful for comparing distributional complexity across ROIs.\n    Not directly interpretable for normality assessment.\n    \"\"\"\n    valid_values = values[~np.isnan(values)]\n    if len(valid_values) == 0:\n        return np.nan\n\n    hist, _ = np.histogram(valid_values, bins=bins, density=True)\n    hist = hist / hist.sum()  # Normalize to probabilities\n    hist = hist[hist &gt; 0]  # Remove zero bins\n    return float(entropy(hist, base=2))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.percentile_5","title":"<code>percentile_5(values)</code>","text":"<p>5th percentile.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def percentile_5(values):\n    \"\"\"5th percentile.\"\"\"\n    return float(np.nanpercentile(values, 5))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.percentile_10","title":"<code>percentile_10(values)</code>","text":"<p>10th percentile.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def percentile_10(values):\n    \"\"\"10th percentile.\"\"\"\n    return float(np.nanpercentile(values, 10))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.percentile_25","title":"<code>percentile_25(values)</code>","text":"<p>25th percentile (Q1).</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def percentile_25(values):\n    \"\"\"25th percentile (Q1).\"\"\"\n    return float(np.nanpercentile(values, 25))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.percentile_50","title":"<code>percentile_50(values)</code>","text":"<p>50th percentile (median).</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def percentile_50(values):\n    \"\"\"50th percentile (median).\"\"\"\n    return float(np.nanpercentile(values, 50))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.percentile_75","title":"<code>percentile_75(values)</code>","text":"<p>75th percentile (Q3).</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def percentile_75(values):\n    \"\"\"75th percentile (Q3).\"\"\"\n    return float(np.nanpercentile(values, 75))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.percentile_90","title":"<code>percentile_90(values)</code>","text":"<p>90th percentile.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def percentile_90(values):\n    \"\"\"90th percentile.\"\"\"\n    return float(np.nanpercentile(values, 90))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.percentile_95","title":"<code>percentile_95(values)</code>","text":"<p>95th percentile.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def percentile_95(values):\n    \"\"\"95th percentile.\"\"\"\n    return float(np.nanpercentile(values, 95))\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.is_strongly_skewed","title":"<code>is_strongly_skewed(values, threshold=0.5)</code>","text":"<p>Whether distribution is strongly skewed.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <code>threshold</code> <code>float</code> <p>Absolute skewness threshold. Default 0.5.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if |skewness| &gt; threshold</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def is_strongly_skewed(values, threshold=0.5):\n    \"\"\"\n    Whether distribution is strongly skewed.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n    threshold : float, optional\n        Absolute skewness threshold. Default 0.5.\n\n    Returns\n    -------\n    bool\n        True if |skewness| &gt; threshold\n    \"\"\"\n    return abs_skewness(values) &gt; threshold\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.is_heavy_tailed","title":"<code>is_heavy_tailed(values, threshold=1.0)</code>","text":"<p>Whether distribution has heavy tails.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <code>threshold</code> <code>float</code> <p>Absolute excess kurtosis threshold. Default 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if |excess_kurtosis| &gt; threshold</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def is_heavy_tailed(values, threshold=1.0):\n    \"\"\"\n    Whether distribution has heavy tails.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n    threshold : float, optional\n        Absolute excess kurtosis threshold. Default 1.0.\n\n    Returns\n    -------\n    bool\n        True if |excess_kurtosis| &gt; threshold\n    \"\"\"\n    return abs_excess_kurtosis(values) &gt; threshold\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.is_bimodal","title":"<code>is_bimodal(values, threshold=0.555)</code>","text":"<p>Whether distribution appears bimodal.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <code>threshold</code> <code>float</code> <p>Bimodality coefficient threshold. Default 0.555.</p> <code>0.555</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if bimodality_coefficient &gt; threshold</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def is_bimodal(values, threshold=0.555):\n    \"\"\"\n    Whether distribution appears bimodal.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n    threshold : float, optional\n        Bimodality coefficient threshold. Default 0.555.\n\n    Returns\n    -------\n    bool\n        True if bimodality_coefficient &gt; threshold\n    \"\"\"\n    return bimodality_coefficient(values) &gt; threshold\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.has_outliers","title":"<code>has_outliers(values, threshold=0.01)</code>","text":"<p>Whether distribution has excessive outliers.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <code>threshold</code> <code>float</code> <p>Proportion threshold for 3SD outliers. Default 0.01 (1%).</p> <code>0.01</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if proportion of 3SD outliers &gt; threshold</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def has_outliers(values, threshold=0.01):\n    \"\"\"\n    Whether distribution has excessive outliers.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n    threshold : float, optional\n        Proportion threshold for 3SD outliers. Default 0.01 (1%).\n\n    Returns\n    -------\n    bool\n        True if proportion of 3SD outliers &gt; threshold\n    \"\"\"\n    return prop_outliers_3sd(values) &gt; threshold\n</code></pre>"},{"location":"api/#parcellate.metrics.volume.fails_normality","title":"<code>fails_normality(values)</code>","text":"<p>Whether distribution fails normality tests.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array - like</code> <p>Within-ROI voxel/vertex values</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if Shapiro-Wilk p &lt; 0.05 (if available), else D'Agostino p &lt; 0.05</p> Notes <p>Prioritizes Shapiro-Wilk (more powerful) when n \u2264 5000. Falls back to D'Agostino-Pearson for larger samples.</p> Source code in <code>src/parcellate/metrics/volume.py</code> <pre><code>def fails_normality(values):\n    \"\"\"\n    Whether distribution fails normality tests.\n\n    Parameters\n    ----------\n    values : array-like\n        Within-ROI voxel/vertex values\n\n    Returns\n    -------\n    bool\n        True if Shapiro-Wilk p &lt; 0.05 (if available), else D'Agostino p &lt; 0.05\n\n    Notes\n    -----\n    Prioritizes Shapiro-Wilk (more powerful) when n \u2264 5000.\n    Falls back to D'Agostino-Pearson for larger samples.\n    \"\"\"\n    shapiro_p_val = shapiro_p(values)\n    if not np.isnan(shapiro_p_val):\n        return shapiro_p_val &lt; 0.05\n\n    dagostino_p_val = dagostino_p(values)\n    if not np.isnan(dagostino_p_val):\n        return dagostino_p_val &lt; 0.05\n\n    return False  # If no test available, default to False\n</code></pre>"},{"location":"api/#utilities","title":"Utilities","text":""},{"location":"api/#parcellate.utils.image","title":"<code>image</code>","text":"<p>Utility functions for image handling</p>"},{"location":"cat12_guide/","title":"CAT12 pipeline guide","text":"<p>This guide covers how to use <code>parcellate</code> with CAT12 preprocessing outputs.</p>"},{"location":"cat12_guide/#expected-input-layout","title":"Expected input layout","text":"<p><code>parcellate</code> searches for CAT12 outputs under <code>bids_dir</code> following this structure:</p> <pre><code>bids_dir/\n\u2514\u2500\u2500 sub-&lt;label&gt;/\n    \u2514\u2500\u2500 [ses-&lt;label&gt;/]\n        \u2514\u2500\u2500 anat/\n            \u251c\u2500\u2500 mwp1&lt;basename&gt;.nii.gz   # gray matter (GM) modulated\n            \u251c\u2500\u2500 mwp2&lt;basename&gt;.nii.gz   # white matter (WM) modulated\n            \u251c\u2500\u2500 wct&lt;basename&gt;.nii.gz    # cortical thickness\n            \u2514\u2500\u2500 cat_&lt;basename&gt;.xml      # CAT12 report (optional; for TIV)\n</code></pre> <p>The subdirectory <code>anat/</code> can be nested further (e.g. inside a <code>CAT12/</code> folder) \u2014 the loader searches recursively.</p>"},{"location":"cat12_guide/#tissue-types","title":"Tissue types","text":"File pattern Tissue type Entity in output <code>mwp1*</code> Gray matter <code>tissue-GM</code> <code>mwp2*</code> White matter <code>tissue-WM</code> <code>wct*</code> Cortical thickness <code>tissue-CT</code>"},{"location":"cat12_guide/#minimal-configuration","title":"Minimal configuration","text":"<pre><code># cat12_config.toml\ninput_root = \"/data/cat12_derivatives\"\noutput_dir = \"/data/parcellations\"\n\n[[atlases]]\nname = \"schaefer400\"\npath = \"/atlases/Schaefer2018_400Parcels_7Networks_order_FSLMNI152_1mm.nii.gz\"\nlut  = \"/atlases/Schaefer2018_400Parcels_7Networks_order_FSLMNI152.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n</code></pre> <p>Run: <pre><code>parcellate /data/cat12_derivatives /data/parcellations participant \\\n    --pipeline cat12 \\\n    --config cat12_config.toml\n</code></pre></p>"},{"location":"cat12_guide/#output-structure","title":"Output structure","text":"<p>Results are written under <code>output_dir/cat12/</code>:</p> <pre><code>output_dir/\n\u2514\u2500\u2500 cat12/\n    \u2514\u2500\u2500 sub-&lt;label&gt;/\n        \u2514\u2500\u2500 [ses-&lt;label&gt;/]\n            \u2514\u2500\u2500 anat/\n                \u2514\u2500\u2500 atlas-&lt;name&gt;/\n                    \u251c\u2500\u2500 sub-&lt;label&gt;_[ses-&lt;label&gt;]_atlas-&lt;name&gt;_space-&lt;space&gt;_tissue-GM_mask-gm_parc.tsv\n                    \u251c\u2500\u2500 sub-&lt;label&gt;_[ses-&lt;label&gt;]_atlas-&lt;name&gt;_space-&lt;space&gt;_tissue-GM_mask-gm_parc.json\n                    \u251c\u2500\u2500 sub-&lt;label&gt;_[ses-&lt;label&gt;]_atlas-&lt;name&gt;_space-&lt;space&gt;_tissue-WM_mask-gm_parc.tsv\n                    \u251c\u2500\u2500 ...\n                    \u2514\u2500\u2500 sub-&lt;label&gt;_[ses-&lt;label&gt;]_tiv.tsv    # if XML report found\n</code></pre> <p>Each <code>.tsv</code> file contains one row per atlas region with columns:</p> Column Description <code>index</code> Integer region index (from the lookup table). <code>label</code> Region name (from the lookup table). <code>vol_TIV</code> Total Intracranial Volume in cm\u00b3 (if XML report available). stat columns One column per statistic in the selected tier. <p>Each <code>.json</code> sidecar records provenance: original file, atlas, mask, thresholds, software version, and timestamp.</p>"},{"location":"cat12_guide/#masking","title":"Masking","text":"<p>CAT12 defaults to the built-in MNI152 gray-matter mask (<code>mask = \"gm\"</code>). Override with <code>--mask</code>:</p> <pre><code># Use white matter mask instead\nparcellate /bids /out participant --pipeline cat12 --mask wm --config cfg.toml\n\n# Use a custom probability map with 50% threshold\nparcellate /bids /out participant --pipeline cat12 \\\n    --mask /path/to/custom_gm.nii.gz \\\n    --mask-threshold 0.5 \\\n    --config cfg.toml\n</code></pre>"},{"location":"cat12_guide/#tiv-extraction","title":"TIV extraction","text":"<p>When CAT12 XML report files (<code>cat_*.xml</code>) are found alongside the NIfTI outputs, <code>parcellate</code> automatically extracts the Total Intracranial Volume and:</p> <ol> <li>Appends a <code>vol_TIV</code> column to each parcellation TSV.</li> <li>Writes a standalone <code>&lt;context&gt;_tiv.tsv</code> file.</li> </ol> <p>No extra configuration is required.</p>"},{"location":"cat12_guide/#full-configuration-reference","title":"Full configuration reference","text":"<pre><code>input_root = \"/data/cat12\"          # required\noutput_dir = \"/data/parcellations\"  # required\n\n# Participant / session filters\nsubjects = [\"sub-01\", \"sub-02\"]     # optional; default = all\nsessions = [\"ses-01\"]               # optional; default = all\n\n# Masking\nmask = \"gm\"                         # gm | wm | brain | /path/to/mask.nii.gz\nmask_threshold = 0.0                # float; voxels with mask &gt; threshold are included\n\n# Statistics\nstat_tier = \"extended\"              # core | extended | diagnostic | all\n\n# Execution\nforce = false                       # overwrite existing outputs\nlog_level = \"INFO\"                  # DEBUG | INFO | WARNING | ERROR\nn_jobs = 4                          # within-subject parallelism (threads)\nn_procs = 2                         # across-subject parallelism (processes)\n\n[[atlases]]\nname  = \"schaefer400\"\npath  = \"/atlases/Schaefer400.nii.gz\"\nlut   = \"/atlases/Schaefer400.tsv\"\nspace = \"MNI152NLin2009cAsym\"       # must match CAT12 output space\n# resolution = \"1mm\"               # optional BIDS entity (res-*)\n# atlas_threshold = 0.0            # for 4D probabilistic atlases\n</code></pre>"},{"location":"cli_reference/","title":"CLI reference","text":"<p><code>parcellate</code> ships with a BIDS App-compatible command-line interface.</p>"},{"location":"cli_reference/#bids-app-interface-recommended","title":"BIDS App interface (recommended)","text":"<pre><code>parcellate &lt;bids_dir&gt; &lt;output_dir&gt; &lt;analysis_level&gt; --pipeline PIPELINE [OPTIONS]\n</code></pre>"},{"location":"cli_reference/#positional-arguments","title":"Positional arguments","text":"Argument Description <code>bids_dir</code> Root directory of the preprocessing derivatives (CAT12 or QSIRecon output tree). <code>output_dir</code> Destination directory where parcellation results are written. <code>analysis_level</code> Level of analysis. Only <code>participant</code> is supported at this time."},{"location":"cli_reference/#required-options","title":"Required options","text":"Flag Description <code>--pipeline {cat12,qsirecon}</code> Preprocessing pipeline that produced the input data."},{"location":"cli_reference/#participant-session-selection","title":"Participant / session selection","text":"Flag Description <code>--participant-label LABEL [LABEL \u2026]</code> Process only these participants (without <code>sub-</code> prefix). Default: all. <code>--session-label ID [ID \u2026]</code> Process only these sessions (without <code>ses-</code> prefix). Default: all."},{"location":"cli_reference/#configuration","title":"Configuration","text":"Flag Description <code>--config CONFIG.toml</code> Path to a TOML file providing atlas definitions and pipeline defaults. <code>--atlas-config FILE [FILE \u2026]</code> One or more TOML files defining atlases (overrides <code>[[atlases]]</code> in <code>--config</code>)."},{"location":"cli_reference/#processing-options","title":"Processing options","text":"Flag Default Description <code>--mask {gm,wm,brain}</code> / <code>PATH</code> <code>gm</code> (CAT12) / none (QSIRecon) Mask to restrict voxels during parcellation. Accepts built-in MNI152 names or a path to a NIfTI mask. <code>--mask-threshold FLOAT</code> <code>0.0</code> Minimum mask value to include a voxel (strict <code>&gt;</code>). Useful with probability maps. <code>--stat-tier {core,extended,diagnostic,all}</code> <code>diagnostic</code> Statistics tier to compute (see Metrics reference). <code>--force</code> <code>False</code> Overwrite existing parcellation outputs. <code>--log-level LEVEL</code> <code>INFO</code> Logging verbosity (<code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>). <code>--n-jobs N</code> <code>1</code> Parallel jobs for within-subject parcellation (thread pool). <code>--n-procs N</code> <code>1</code> Parallel processes for across-subject parcellation (process pool)."},{"location":"cli_reference/#examples","title":"Examples","text":"<pre><code># Minimal: one participant, all sessions, default settings\nparcellate /data/cat12 /data/parcellations participant \\\n    --pipeline cat12 \\\n    --participant-label 01 \\\n    --config atlases.toml\n\n# Multiple participants with WM mask and extended statistics\nparcellate /data/cat12 /data/parcellations participant \\\n    --pipeline cat12 \\\n    --participant-label 01 02 03 \\\n    --session-label ses-01 \\\n    --mask wm \\\n    --stat-tier extended \\\n    --config atlases.toml\n\n# QSIRecon with parallelism\nparcellate /data/qsirecon /data/parcellations participant \\\n    --pipeline qsirecon \\\n    --config atlases.toml \\\n    --stat-tier core \\\n    --n-jobs 4 \\\n    --n-procs 2\n</code></pre>"},{"location":"cli_reference/#legacy-subcommand-interface-deprecated","title":"Legacy subcommand interface (deprecated)","text":"<p>The old subcommand-based invocation still works but emits a <code>DeprecationWarning</code>. It will be removed in a future major release.</p> <pre><code># Deprecated \u2014 use BIDS App interface instead\nparcellate cat12 config.toml\nparcellate qsirecon config.toml\n</code></pre> <p>Legacy invocations accept the same optional flags as the BIDS App interface (<code>--input-root</code>, <code>--output-dir</code>, <code>--subjects</code>, <code>--sessions</code>, etc.) directly after the subcommand.</p>"},{"location":"cli_reference/#toml-configuration-file","title":"TOML configuration file","text":"<p>Atlas definitions and pipeline defaults can be provided in a TOML file:</p> <pre><code>input_root = \"/data/cat12\"\noutput_dir = \"/data/parcellations\"\nsubjects = [\"sub-01\", \"sub-02\"]   # optional filter\nsessions = [\"ses-01\"]             # optional filter\nmask = \"gm\"                       # gm | wm | brain | /path/to/mask.nii.gz\nmask_threshold = 0.5              # &gt;0 voxels included when using probability maps\nstat_tier = \"extended\"            # core | extended | diagnostic | all\nforce = false\nlog_level = \"INFO\"\nn_jobs = 4\nn_procs = 2\n\n[[atlases]]\nname = \"schaefer400\"\npath = \"/path/to/Schaefer2018_400Parcels_7Networks_order_FSLMNI152_1mm.nii.gz\"\nlut  = \"/path/to/Schaefer2018_400Parcels_7Networks_order_FSLMNI152.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n\n[[atlases]]\nname = \"aal\"\npath = \"/path/to/AAL3v1.nii.gz\"\nlut  = \"/path/to/AAL3v1.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n</code></pre> <p>CLI flags always override values from the TOML file.</p>"},{"location":"cli_reference/#parcellate-cat12-standalone-deprecated","title":"<code>parcellate-cat12</code> (standalone, deprecated)","text":"<p>The <code>parcellate-cat12</code> entry point is a separate CSV-based CLI for CAT12 that reads configuration from environment variables.  It is deprecated and will be removed in a future release.  Migrate to <code>parcellate cat12 config.toml</code> or the BIDS App interface.</p>"},{"location":"configuration/","title":"Configuration reference","text":"<p><code>parcellate</code> is configured through TOML files. CLI flags always override values from the TOML file.</p>"},{"location":"configuration/#file-structure","title":"File structure","text":"<p>A configuration file can contain top-level keys (pipeline settings) and one or more <code>[[atlases]]</code> sections:</p> <pre><code># Pipeline settings\ninput_root = \"/data/derivatives\"\noutput_dir  = \"/data/parcellations\"\n\n[[atlases]]\nname  = \"schaefer400\"\npath  = \"/atlases/Schaefer400.nii.gz\"\nlut   = \"/atlases/Schaefer400.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n</code></pre> <p>Pass the file with <code>--config</code>:</p> <pre><code>parcellate /data/cat12 /data/out participant --pipeline cat12 --config my_config.toml\n</code></pre>"},{"location":"configuration/#top-level-settings","title":"Top-level settings","text":""},{"location":"configuration/#paths","title":"Paths","text":"Key Type Required Description <code>input_root</code> string Yes Root directory of preprocessing derivatives. Overridden by the <code>bids_dir</code> positional argument on the CLI. <code>output_dir</code> string Yes Destination directory for parcellation outputs."},{"location":"configuration/#participant-session-filters","title":"Participant / session filters","text":"Key Type Default Description <code>subjects</code> list of strings all Subject IDs to process (with or without <code>sub-</code> prefix). <code>sessions</code> list of strings all Session IDs to process (with or without <code>ses-</code> prefix). <pre><code>subjects = [\"sub-01\", \"sub-02\"]\nsessions = [\"ses-baseline\"]\n</code></pre>"},{"location":"configuration/#masking","title":"Masking","text":"Key Type Default Description <code>mask</code> string <code>\"gm\"</code> (CAT12) / none (QSIRecon) Brain mask. Accepts built-in names (<code>gm</code>, <code>wm</code>, <code>brain</code>) or an absolute path to a NIfTI file. <code>mask_threshold</code> float <code>0.0</code> Minimum mask value to include a voxel (strict <code>&gt;</code>). Useful with probabilistic masks. <pre><code># Built-in grey-matter mask (CAT12 default)\nmask = \"gm\"\nmask_threshold = 0.0\n\n# Custom probabilistic mask at 50% threshold\nmask = \"/path/to/custom_gm.nii.gz\"\nmask_threshold = 0.5\n</code></pre>"},{"location":"configuration/#statistics","title":"Statistics","text":"Key Type Default Description <code>stat_tier</code> string <code>\"diagnostic\"</code> Tier of statistics to compute. One of <code>core</code>, <code>extended</code>, <code>diagnostic</code>, <code>all</code>. See Metrics reference. <pre><code>stat_tier = \"extended\"   # 21 statistics \u2014 good balance for production runs\n</code></pre>"},{"location":"configuration/#execution","title":"Execution","text":"Key Type Default Description <code>force</code> boolean <code>false</code> Overwrite existing output files. When <code>false</code>, existing files are skipped. <code>log_level</code> string <code>\"INFO\"</code> Logging verbosity. One of <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>. <code>n_jobs</code> integer <code>1</code> Number of parallel threads for within-subject parcellation. <code>n_procs</code> integer <code>1</code> Number of parallel processes for across-subject parcellation. <pre><code>force     = false\nlog_level = \"INFO\"\nn_jobs    = 4\nn_procs   = 2\n</code></pre>"},{"location":"configuration/#atlas-definitions-atlases","title":"Atlas definitions (<code>[[atlases]]</code>)","text":"<p>Each <code>[[atlases]]</code> block defines one atlas. Multiple atlases can be stacked in a single file.</p>"},{"location":"configuration/#required-keys","title":"Required keys","text":"Key Type Description <code>name</code> string Short identifier embedded in output filenames (<code>atlas-&lt;name&gt;</code>). <code>path</code> string Absolute path to the atlas NIfTI file (3D integer-labeled or 4D probabilistic)."},{"location":"configuration/#optional-keys","title":"Optional keys","text":"Key Type Default Description <code>lut</code> string \u2014 Path to a lookup table TSV with <code>index</code> and <code>label</code> columns. <code>space</code> string \u2014 BIDS space entity (<code>MNI152NLin2009cAsym</code>, <code>MNI152NLin6Asym</code>, \u2026). Must match the scalar map space. <code>resolution</code> string \u2014 Optional BIDS <code>res-</code> entity (e.g., <code>\"1mm\"</code>). Informational only. <code>atlas_threshold</code> float <code>0.0</code> For 4D probabilistic atlases: minimum voxel probability to include (strict <code>&gt;</code>). <pre><code>[[atlases]]\nname            = \"schaefer400\"\npath            = \"/atlases/Schaefer400.nii.gz\"\nlut             = \"/atlases/Schaefer400.tsv\"\nspace           = \"MNI152NLin2009cAsym\"\n\n[[atlases]]\nname            = \"xtract\"\npath            = \"/atlases/XTRACT_tracts.nii.gz\"   # 4D probabilistic\nlut             = \"/atlases/XTRACT.tsv\"\nspace           = \"MNI152NLin6Asym\"\natlas_threshold = 0.25\n</code></pre>"},{"location":"configuration/#lookup-table-format","title":"Lookup table format","text":"<p>The LUT file is a tab-separated file with at minimum these two columns:</p> Column Description <code>index</code> Integer label value in the atlas NIfTI. <code>label</code> Human-readable region name. <p>Additional columns are allowed and preserved in the output TSV.</p> <p>Example <code>atlas.tsv</code>: <pre><code>index   label\n1   Left-Frontal-Pole\n2   Right-Frontal-Pole\n3   Left-Superior-Frontal-Gyrus\n</code></pre></p>"},{"location":"configuration/#providing-atlases-separately-atlas-config","title":"Providing atlases separately (<code>--atlas-config</code>)","text":"<p>Atlas definitions can be split into a separate TOML file and passed with <code>--atlas-config</code>. This is convenient when reusing the same atlas set across multiple pipeline runs.</p> <pre><code># atlases.toml \u2014 atlas definitions only\n[[atlases]]\nname  = \"schaefer400\"\npath  = \"/atlases/Schaefer400.nii.gz\"\nlut   = \"/atlases/Schaefer400.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n</code></pre> <pre><code>parcellate /data/cat12 /data/out participant \\\n    --pipeline cat12 \\\n    --config pipeline.toml \\\n    --atlas-config atlases.toml\n</code></pre> <p>When <code>--atlas-config</code> is supplied, it overrides the <code>[[atlases]]</code> sections in <code>--config</code>.</p>"},{"location":"configuration/#complete-example","title":"Complete example","text":"<pre><code># full_config.toml\n\ninput_root = \"/data/cat12\"\noutput_dir = \"/data/parcellations\"\n\nsubjects = [\"sub-01\", \"sub-02\", \"sub-03\"]\nsessions = [\"ses-baseline\"]\n\nmask           = \"gm\"\nmask_threshold = 0.0\n\nstat_tier = \"extended\"\n\nforce     = false\nlog_level = \"INFO\"\nn_jobs    = 4\nn_procs   = 2\n\n[[atlases]]\nname  = \"schaefer400\"\npath  = \"/atlases/Schaefer2018_400Parcels_7Networks_order_FSLMNI152_1mm.nii.gz\"\nlut   = \"/atlases/Schaefer2018_400Parcels_7Networks_order_FSLMNI152.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n\n[[atlases]]\nname  = \"aal3\"\npath  = \"/atlases/AAL3v1.nii.gz\"\nlut   = \"/atlases/AAL3v1.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n</code></pre> <p>Run: <pre><code>parcellate /data/cat12 /data/parcellations participant \\\n    --pipeline cat12 \\\n    --config full_config.toml\n</code></pre></p>"},{"location":"getting_started/","title":"Getting started","text":"<p>This guide walks through installing <code>parcellate</code> and running your first parcellation.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<pre><code>pip install parcellate\n</code></pre> <p>For optional <code>.env</code> file support in the legacy <code>parcellate-cat12</code> CLI:</p> <pre><code>pip install parcellate[dotenv]\n</code></pre> <p>Alternatively, install from a local checkout:</p> <pre><code>git clone https://github.com/GalKepler/parcellate.git\ncd parcellate\npip install -e .\n</code></pre>"},{"location":"getting_started/#verifying-your-environment","title":"Verifying your environment","text":"<p><code>parcellate</code> depends on scientific Python libraries such as Nibabel, NumPy, and pandas. To confirm your installation, open a Python shell and import the core components:</p> <pre><code>&gt;&gt;&gt; import nibabel as nib\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; from parcellate import VolumetricParcellator\n</code></pre> <p>If those imports succeed, you can move on to the usage examples below.</p>"},{"location":"getting_started/#quick-start-bids-app-cli","title":"Quick start: BIDS App (CLI)","text":"<p><code>parcellate</code> follows the BIDS App convention. The basic invocation is:</p> <pre><code>parcellate &lt;bids_dir&gt; &lt;output_dir&gt; participant --pipeline {cat12,qsirecon} --config config.toml\n</code></pre>"},{"location":"getting_started/#cat12-example","title":"CAT12 example","text":"<p>Create a minimal TOML configuration file:</p> <pre><code># atlases.toml\n[[atlases]]\nname  = \"schaefer400\"\npath  = \"/atlases/Schaefer2018_400Parcels_7Networks_order_FSLMNI152_1mm.nii.gz\"\nlut   = \"/atlases/Schaefer2018_400Parcels_7Networks_order_FSLMNI152.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n</code></pre> <p>Then run:</p> <pre><code>parcellate /data/cat12_derivatives /data/parcellations participant \\\n    --pipeline cat12 \\\n    --config atlases.toml\n</code></pre> <p>For a detailed guide to CAT12 inputs and outputs, see CAT12 pipeline guide.</p>"},{"location":"getting_started/#qsirecon-example","title":"QSIRecon example","text":"<pre><code># atlases.toml\n[[atlases]]\nname  = \"jhu\"\npath  = \"/atlases/JHU-ICBM-labels-1mm.nii.gz\"\nlut   = \"/atlases/JHU-ICBM-labels-1mm.tsv\"\nspace = \"MNI152NLin6Asym\"\n</code></pre> <pre><code>parcellate /data/qsirecon_derivatives /data/parcellations participant \\\n    --pipeline qsirecon \\\n    --config atlases.toml \\\n    --stat-tier core\n</code></pre> <p>For a detailed guide to QSIRecon inputs and outputs, see QSIRecon pipeline guide.</p>"},{"location":"getting_started/#quick-start-python-api","title":"Quick start: Python API","text":"<p>The snippet below demonstrates the essential steps: load an atlas, connect a lookup table, and compute parcel-wise statistics.</p> <pre><code>import nibabel as nib\nimport pandas as pd\nfrom parcellate import VolumetricParcellator\n\n# Load a labeled atlas and its lookup table\natlas = nib.load(\"atlas.nii.gz\")\nlut = pd.read_csv(\"atlas_lut.tsv\", sep=\"\\t\")\n\n# Create the parcellator\nparcellator = VolumetricParcellator(atlas_img=atlas, lut=lut)\n\n# Fit and evaluate a scalar map\nparcellator.fit(\"subject_T1w.nii.gz\")\nregional_stats = parcellator.transform(\"subject_T1w.nii.gz\")\nprint(regional_stats.head())\n</code></pre> <p>The output is a <code>pandas.DataFrame</code> with one row per atlas region and one column per statistic. By default all 45 built-in statistics are computed. Use <code>stat_tier=\"core\"</code> or <code>stat_tier=\"extended\"</code> to compute fewer columns \u2014 see Metrics reference.</p>"},{"location":"getting_started/#next-steps","title":"Next steps","text":"Guide Description CAT12 pipeline guide Input layout, output format, masking, TIV extraction QSIRecon pipeline guide Input layout, output format, probabilistic atlases CLI reference All CLI flags and options Metrics reference All 45 statistics organized by tier Configuration reference TOML configuration file format Troubleshooting Common errors and solutions"},{"location":"metrics_reference/","title":"Metrics reference","text":"<p><code>parcellate</code> ships with 45 built-in statistics organised into named tiers. Select a tier via <code>stat_tier</code> in Python, TOML config, or the <code>--stat-tier</code> CLI flag.</p>"},{"location":"metrics_reference/#tiers-at-a-glance","title":"Tiers at a glance","text":"Tier Count Use case <code>core</code> 6 Fast exploration, large cohorts <code>extended</code> 21 Production pipelines <code>diagnostic</code> / <code>all</code> 45 Data quality, distribution inspection <p>Default: <code>diagnostic</code> (all 45 statistics).</p>"},{"location":"metrics_reference/#core-tier-6-statistics","title":"Core tier (6 statistics)","text":"<p>The six most common descriptors. Suitable when output file size or compute time matters most.</p> Name Description <code>mean</code> Arithmetic mean (<code>np.nanmean</code>). <code>std</code> Standard deviation (<code>np.nanstd</code>). <code>median</code> Median (<code>np.nanmedian</code>). <code>volume_mm3</code> Region volume in mm\u00b3 (uses voxel dimensions from the image header). <code>voxel_count</code> Number of non-background voxels in the region. <code>sum</code> Sum of voxel intensities."},{"location":"metrics_reference/#extended-tier-21-statistics","title":"Extended tier (21 statistics)","text":"<p>Everything in core plus robust/filtered estimates and basic shape descriptors. A good default for production parcellation pipelines.</p>"},{"location":"metrics_reference/#robust-filtered-means-and-dispersions","title":"Robust / filtered means and dispersions","text":"Name Description <code>robust_mean</code> Mean after removing voxels more than 3 median absolute deviations (MAD) from the median. <code>robust_std</code> Standard deviation of the MAD-filtered sample. <code>mad_median</code> Median absolute deviation from the median. <code>z_filtered_mean</code> Mean after discarding voxels with <code>|z| &gt; 3</code>. <code>z_filtered_std</code> Standard deviation of the z-score-filtered sample. <code>iqr_filtered_mean</code> Mean after removing voxels outside the interquartile fence. <code>iqr_filtered_std</code> Standard deviation of the IQR-filtered sample. <code>cv</code> Coefficient of variation: <code>std / mean</code>. <code>robust_cv</code> Robust coefficient of variation: <code>IQR / median</code>."},{"location":"metrics_reference/#shape","title":"Shape","text":"Name Description <code>skewness</code> Third standardised moment. Positive = right-skewed. <code>excess_kurtosis</code> Fourth standardised moment minus 3. Positive = heavier tails than normal."},{"location":"metrics_reference/#key-percentiles","title":"Key percentiles","text":"Name Description <code>percentile_5</code> 5th percentile. <code>percentile_25</code> 25th percentile (Q1). <code>percentile_75</code> 75th percentile (Q3). <code>percentile_95</code> 95th percentile."},{"location":"metrics_reference/#diagnostic-tier-additional-statistics-beyond-extended","title":"Diagnostic tier \u2014 additional statistics (beyond extended)","text":""},{"location":"metrics_reference/#additional-shape-metrics","title":"Additional shape metrics","text":"Name Description <code>quartile_dispersion</code> <code>(Q3 \u2212 Q1) / (Q3 + Q1)</code> \u2014 scale-free dispersion. <code>abs_skewness</code> Absolute value of skewness. <code>abs_excess_kurtosis</code> Absolute value of excess kurtosis. <code>bimodality_coefficient</code> Bimodality coefficient <code>(skewness\u00b2 + 1) / kurtosis</code>. Values &gt; 0.555 suggest bimodality."},{"location":"metrics_reference/#outlier-proportions","title":"Outlier proportions","text":"Name Description <code>prop_outliers_2sd</code> Proportion of voxels more than 2 SD from the mean. <code>prop_outliers_3sd</code> Proportion of voxels more than 3 SD from the mean. <code>prop_outliers_iqr</code> Proportion of voxels outside 1.5 \u00d7 IQR fence (Tukey fences)."},{"location":"metrics_reference/#tail-behaviour","title":"Tail behaviour","text":"Name Description <code>left_tail_mass</code> Proportion of values below <code>mean \u2212 2\u03c3</code>. <code>right_tail_mass</code> Proportion of values above <code>mean + 2\u03c3</code>. <code>tail_asymmetry</code> <code>right_tail_mass \u2212 left_tail_mass</code>. Positive = heavier right tail. <code>excess_tail_mass</code> <code>left_tail_mass + right_tail_mass</code>. Total extreme-value proportion."},{"location":"metrics_reference/#normality-tests","title":"Normality tests","text":"Name Description <code>dagostino_k2</code> D'Agostino K\u00b2 test statistic (combines skewness and kurtosis). <code>dagostino_p</code> P-value for the K\u00b2 test. Small values indicate non-normality. <code>log_dagostino_k2</code> Natural log of <code>dagostino_k2</code> (compresses dynamic range). <code>shapiro_w</code> Shapiro-Wilk W statistic (only for 3 \u2264 n \u2264 5000; <code>NaN</code> otherwise). <code>shapiro_p</code> Shapiro-Wilk p-value. <code>qq_correlation</code> Pearson correlation of sorted values against theoretical normal quantiles. <code>qq_r_squared</code> R\u00b2 of the Q-Q linear fit. Values near 1 indicate normality."},{"location":"metrics_reference/#information-theory","title":"Information theory","text":"Name Description <code>histogram_entropy</code> Shannon entropy of a normalised histogram (20 bins)."},{"location":"metrics_reference/#additional-percentiles","title":"Additional percentiles","text":"Name Description <code>percentile_10</code> 10th percentile. <code>percentile_50</code> 50th percentile (median, same as <code>median</code>). <code>percentile_90</code> 90th percentile."},{"location":"metrics_reference/#boolean-flags","title":"Boolean flags","text":"<p>These columns contain <code>True</code>/<code>False</code> values and are useful for quick QC filtering.</p> Name Threshold <code>is_strongly_skewed</code> <code>|skewness| &gt; 1</code> <code>is_heavy_tailed</code> <code>excess_kurtosis &gt; 1</code> <code>is_bimodal</code> <code>bimodality_coefficient &gt; 0.555</code> <code>has_outliers</code> <code>prop_outliers_iqr &gt; 0.05</code> <code>fails_normality</code> <code>dagostino_p &lt; 0.05</code>"},{"location":"metrics_reference/#using-tiers-in-python","title":"Using tiers in Python","text":"<pre><code>from parcellate import VolumetricParcellator\n\n# Use the 'extended' tier\nparcellator = VolumetricParcellator(\n    atlas_img=\"atlas.nii.gz\",\n    lut=\"atlas_lut.tsv\",\n    stat_tier=\"extended\",\n)\nparcellator.fit(\"subject_T1w.nii.gz\")\ndf = parcellator.transform(\"subject_T1w.nii.gz\")\n# df has columns: index, label, mean, std, median, volume_mm3, ...\n</code></pre>"},{"location":"metrics_reference/#custom-statistics","title":"Custom statistics","text":"<p>You can replace the built-in statistics entirely with your own functions:</p> <pre><code>import numpy as np\nfrom parcellate import VolumetricParcellator\n\nparcellator = VolumetricParcellator(\n    atlas_img=\"atlas.nii.gz\",\n    stat_functions={\n        \"trimmed_mean\": lambda x: float(np.nanmean(x[np.abs(x - np.nanmedian(x)) &lt; 2 * np.nanstd(x)])),\n        \"q90\": lambda x: float(np.nanpercentile(x, 90)),\n    },\n)\n</code></pre> <p>When <code>stat_functions</code> is provided it takes precedence over <code>stat_tier</code>.</p>"},{"location":"metrics_reference/#accessing-tier-lists-programmatically","title":"Accessing tier lists programmatically","text":"<pre><code>from parcellate.metrics import CORE_STATISTICS, EXTENDED_STATISTICS, STATISTIC_TIERS\n\n# Inspect available tiers\nfor tier_name, stats in STATISTIC_TIERS.items():\n    print(f\"{tier_name}: {[s.name for s in stats]}\")\n</code></pre>"},{"location":"qsirecon_guide/","title":"QSIRecon pipeline guide","text":"<p>This guide covers how to use <code>parcellate</code> with QSIRecon dMRI preprocessing outputs.</p>"},{"location":"qsirecon_guide/#expected-input-layout","title":"Expected input layout","text":"<p><code>parcellate</code> searches for QSIRecon outputs under <code>bids_dir</code> following this structure:</p> <pre><code>bids_dir/\n\u2514\u2500\u2500 qsirecon-&lt;workflow&gt;/\n    \u2514\u2500\u2500 sub-&lt;label&gt;/\n        \u2514\u2500\u2500 [ses-&lt;label&gt;/]\n            \u2514\u2500\u2500 dwi/\n                \u2514\u2500\u2500 sub-&lt;label&gt;_[ses-&lt;label&gt;]_space-&lt;space&gt;_model-&lt;model&gt;_param-&lt;param&gt;_dwimap.nii.gz\n</code></pre> <p>Files are discovered by the <code>*_dwimap.nii*</code> glob pattern. BIDS entities (<code>space</code>, <code>model</code>, <code>param</code>, <code>desc</code>) are parsed from the filename automatically.</p>"},{"location":"qsirecon_guide/#required-filename-entities","title":"Required filename entities","text":"Entity Key Example <code>param</code> Diffusion parameter <code>FA</code>, <code>MD</code>, <code>AD</code>, <code>RD</code> <code>space</code> Coordinate space <code>MNI152NLin2009cAsym</code>"},{"location":"qsirecon_guide/#optional-filename-entities","title":"Optional filename entities","text":"Entity Key Example <code>model</code> Reconstruction model <code>csd</code>, <code>dti</code> <code>desc</code> Free-form description <code>preproc</code>"},{"location":"qsirecon_guide/#minimal-configuration","title":"Minimal configuration","text":"<pre><code># qsirecon_config.toml\ninput_root = \"/data/qsirecon_derivatives\"\noutput_dir = \"/data/parcellations\"\n\n[[atlases]]\nname = \"schaefer400\"\npath = \"/atlases/Schaefer400.nii.gz\"\nlut  = \"/atlases/Schaefer400.tsv\"\nspace = \"MNI152NLin2009cAsym\"\n</code></pre> <p>Run: <pre><code>parcellate /data/qsirecon_derivatives /data/parcellations participant \\\n    --pipeline qsirecon \\\n    --config qsirecon_config.toml\n</code></pre></p>"},{"location":"qsirecon_guide/#output-structure","title":"Output structure","text":"<p>Results are written under <code>output_dir/qsirecon-&lt;workflow&gt;/</code>:</p> <pre><code>output_dir/\n\u2514\u2500\u2500 qsirecon-&lt;workflow&gt;/\n    \u2514\u2500\u2500 sub-&lt;label&gt;/\n        \u2514\u2500\u2500 [ses-&lt;label&gt;/]\n            \u2514\u2500\u2500 dwi/\n                \u2514\u2500\u2500 atlas-&lt;name&gt;/\n                    \u251c\u2500\u2500 sub-&lt;label&gt;_atlas-&lt;name&gt;_space-&lt;space&gt;_model-&lt;model&gt;_param-FA_parc.tsv\n                    \u251c\u2500\u2500 sub-&lt;label&gt;_atlas-&lt;name&gt;_space-&lt;space&gt;_model-&lt;model&gt;_param-FA_parc.json\n                    \u2514\u2500\u2500 ...\n</code></pre> <p>Each <code>.tsv</code> file has one row per atlas region with columns:</p> Column Description <code>index</code> Integer region index. <code>label</code> Region name. stat columns One column per statistic in the selected tier."},{"location":"qsirecon_guide/#atlas-space-matching","title":"Atlas space matching","text":"<p>QSIRecon atlases must declare the same <code>space</code> entity as the scalar maps. Unlike the CAT12 interface, there is no default space \u2014 if the atlas definition omits <code>space</code>, only scalar maps without a space entity will be matched to it.</p> <p>Tip: Always set <code>space</code> in your atlas definition to avoid silent mismatches.</p> <pre><code>[[atlases]]\nname  = \"xtract\"\npath  = \"/atlases/xtract_tracts.nii.gz\"   # 4D probabilistic atlas\nlut   = \"/atlases/xtract_lut.tsv\"\nspace = \"MNI152NLin6Asym\"\natlas_threshold = 0.25                    # include only high-confidence voxels\n</code></pre>"},{"location":"qsirecon_guide/#probabilistic-4d-atlases","title":"Probabilistic (4D) atlases","text":"<p>QSIRecon is often used with white-matter tract atlases (e.g. XTRACT) where each region is encoded as a continuous probability volume in a 4D NIfTI. Pass the 4D atlas directly \u2014 <code>parcellate</code> detects the dimensionality automatically.</p> <pre><code>[[atlases]]\nname            = \"xtract\"\npath            = \"/atlases/XTRACT_tracts.nii.gz\"   # 4D\nlut             = \"/atlases/XTRACT.tsv\"\nspace           = \"MNI152NLin6Asym\"\natlas_threshold = 0.25   # only voxels where tract probability &gt; 0.25\n</code></pre>"},{"location":"qsirecon_guide/#full-configuration-reference","title":"Full configuration reference","text":"<pre><code>input_root = \"/data/qsirecon\"       # required\noutput_dir = \"/data/parcellations\"  # required\n\n# Participant / session filters\nsubjects = [\"sub-01\", \"sub-02\"]     # optional; default = all\nsessions = [\"ses-01\"]               # optional; default = all\n\n# Masking (optional for dMRI; no built-in default)\nmask = \"/path/to/brain_mask.nii.gz\"\nmask_threshold = 0.5\n\n# Statistics\nstat_tier = \"core\"                  # core | extended | diagnostic | all\n\n# Execution\nforce = false\nlog_level = \"INFO\"\nn_jobs = 4\nn_procs = 2\n\n[[atlases]]\nname            = \"schaefer400\"\npath            = \"/atlases/Schaefer400.nii.gz\"\nlut             = \"/atlases/Schaefer400.tsv\"\nspace           = \"MNI152NLin2009cAsym\"\n\n[[atlases]]\nname            = \"xtract\"\npath            = \"/atlases/XTRACT_tracts.nii.gz\"\nlut             = \"/atlases/XTRACT.tsv\"\nspace           = \"MNI152NLin6Asym\"\natlas_threshold = 0.25\n</code></pre>"},{"location":"troubleshooting/","title":"Troubleshooting","text":"<p>This page covers common errors, warnings, and their solutions.</p>"},{"location":"troubleshooting/#cli-errors","title":"CLI errors","text":""},{"location":"troubleshooting/#error-the-following-arguments-are-required-pipeline","title":"<code>error: the following arguments are required: --pipeline</code>","text":"<p>Cause: The BIDS App interface requires <code>--pipeline</code> to be specified.</p> <p>Fix: <pre><code># Add --pipeline {cat12,qsirecon}\nparcellate /data/cat12 /data/out participant --pipeline cat12 --config atlases.toml\n</code></pre></p>"},{"location":"troubleshooting/#error-argument-analysis_level-invalid-choice-group","title":"<code>error: argument analysis_level: invalid choice: 'group'</code>","text":"<p>Cause: Only <code>participant</code>-level analysis is supported.</p> <p>Fix: Use <code>participant</code> as the analysis level: <pre><code>parcellate /data/cat12 /data/out participant --pipeline cat12 ...\n</code></pre></p>"},{"location":"troubleshooting/#deprecationwarning-parcellate-cat12-is-deprecated","title":"<code>DeprecationWarning: 'parcellate cat12' is deprecated</code>","text":"<p>Cause: You are using the old subcommand syntax (<code>parcellate cat12 config.toml</code>).</p> <p>Fix: Migrate to the BIDS App interface: <pre><code># Old (deprecated)\nparcellate cat12 config.toml\n\n# New\nparcellate /data/cat12 /data/out participant --pipeline cat12 --config config.toml\n</code></pre></p>"},{"location":"troubleshooting/#deprecationwarning-the-parcellate-cat12-command-is-deprecated","title":"<code>DeprecationWarning: The 'parcellate-cat12' command is deprecated</code>","text":"<p>Cause: You are using the CSV-based <code>parcellate-cat12</code> entry point.</p> <p>Fix: Migrate to the BIDS App interface. See the CAT12 guide for the equivalent configuration.</p>"},{"location":"troubleshooting/#atlas-errors","title":"Atlas errors","text":""},{"location":"troubleshooting/#valueerror-unknown-stat_tier-valid-tiers-core-extended-diagnostic-all","title":"<code>ValueError: Unknown stat_tier \"\u2026\". Valid tiers: \"core\", \"extended\", \"diagnostic\", \"all\".</code>","text":"<p>Cause: An unrecognized value was passed to <code>--stat-tier</code> (CLI) or <code>stat_tier</code> (TOML/Python).</p> <p>Fix: Use one of the valid tiers: <pre><code>--stat-tier core      # 6 statistics\n--stat-tier extended  # 21 statistics\n--stat-tier diagnostic  # all 45 (default)\n</code></pre></p>"},{"location":"troubleshooting/#missingstatisticalfunctionerror","title":"<code>MissingStatisticalFunctionError</code>","text":"<p>Cause: <code>stat_functions</code> was provided but is empty, and no fallback is available.</p> <p>Fix: Provide at least one callable in <code>stat_functions</code>, or remove the argument to use the default tier.</p>"},{"location":"troubleshooting/#valueerror-atlas-space-not-found-in-any-scalar-map","title":"<code>ValueError: Atlas space \"\u2026\" not found in any scalar map</code>","text":"<p>Cause: The atlas <code>space</code> entry in the config does not match the <code>space-</code> entity in any discovered scalar map filenames.</p> <p>Fix: Check that the <code>space</code> value in the atlas definition exactly matches the space encoded in the input filenames. For CAT12, the default space is <code>MNI152NLin2009cAsym</code>. For QSIRecon, the space is embedded in the <code>*_dwimap.nii.gz</code> filename.</p>"},{"location":"troubleshooting/#missinglutcolumnserror","title":"<code>MissingLUTColumnsError</code>","text":"<p>Cause: The lookup table TSV does not have the required <code>index</code> and/or <code>label</code> columns.</p> <p>Fix: Ensure your LUT has at minimum: <pre><code>index   label\n1       Left-Frontal-Pole\n2       Right-Frontal-Pole\n</code></pre></p>"},{"location":"troubleshooting/#parcellatornotfittederror","title":"<code>ParcellatorNotFittedError</code>","text":"<p>Cause: <code>transform()</code> was called before <code>fit()</code>.</p> <p>Fix: <pre><code>parcellator.fit(\"subject_T1w.nii.gz\")\nstats = parcellator.transform(\"subject_T1w.nii.gz\")\n</code></pre></p>"},{"location":"troubleshooting/#input-discovery-errors","title":"Input discovery errors","text":""},{"location":"troubleshooting/#no-subjects-found-empty-run","title":"No subjects found / empty run","text":"<p>Cause: <code>parcellate</code> could not find any valid input files under <code>bids_dir</code>.</p> <p>Checklist: 1. Verify the directory structure matches the expected layout (see CAT12 guide or QSIRecon guide). 2. For CAT12: check that <code>mwp1*.nii.gz</code> / <code>mwp2*.nii.gz</code> files exist under <code>sub-*/anat/</code>. 3. For QSIRecon: check that <code>*_dwimap.nii.gz</code> files exist under <code>qsirecon-*/sub-*/dwi/</code>. 4. Confirm <code>--participant-label</code> values match directory names (without the <code>sub-</code> prefix).</p>"},{"location":"troubleshooting/#filenotfounderror-for-atlas-or-mask-path","title":"<code>FileNotFoundError</code> for atlas or mask path","text":"<p>Cause: A path specified in the config or CLI does not exist.</p> <p>Fix: Use absolute paths. Relative paths are resolved from the current working directory, which may differ depending on how <code>parcellate</code> is invoked.</p>"},{"location":"troubleshooting/#resampling-space-errors","title":"Resampling / space errors","text":""},{"location":"troubleshooting/#outputs-contain-unexpected-nan-values","title":"Outputs contain unexpected NaN values","text":"<p>Cause: The atlas and scalar map spaces do not align after resampling.</p> <p>Checklist: 1. Confirm <code>space</code> in the atlas definition matches the space of the scalar map. 2. If using a custom mask, ensure it is in the same space as the scalar maps. 3. Check <code>atlas_threshold</code> \u2014 if set too high, all voxels in a region may be excluded, producing NaN statistics.</p>"},{"location":"troubleshooting/#slow-parcellation-high-memory-usage","title":"Slow parcellation / high memory usage","text":"<p>Cause: The default <code>resampling_target=\"data\"</code> resamples the atlas into scalar-map space. If the scalar map is very high resolution, this creates large in-memory arrays.</p> <p>Fix (Python API): <pre><code>parcellator = VolumetricParcellator(\n    atlas_img=\"atlas.nii.gz\",\n    resampling_target=\"labels\",  # resample scalar maps to atlas resolution\n)\n</code></pre></p> <p>Fix (TOML): <code>resampling_target</code> is not yet exposed as a TOML key. Use <code>n_jobs</code> / <code>n_procs</code> to manage resource usage.</p>"},{"location":"troubleshooting/#parallelism","title":"Parallelism","text":""},{"location":"troubleshooting/#brokenprocesspool-worker-crash","title":"<code>BrokenProcessPool</code> / worker crash","text":"<p>Cause: A subprocess died unexpectedly, often due to running out of memory.</p> <p>Fix: Reduce <code>n_procs</code> (across-subject processes) or <code>n_jobs</code> (within-subject threads): <pre><code>n_jobs  = 2\nn_procs = 1\n</code></pre></p>"},{"location":"troubleshooting/#getting-help","title":"Getting help","text":"<p>If none of the above resolves your issue, please open a GitHub issue at:</p> <pre><code>https://github.com/GalKepler/parcellate/issues\n</code></pre> <p>Include: - The full error traceback - The TOML config (redact sensitive paths) - The output of <code>parcellate --version</code> - The Python and OS versions (<code>python --version</code>, <code>uname -a</code>)</p>"},{"location":"usage/","title":"Usage guide","text":"<p>The <code>VolumetricParcellator</code> orchestrates atlas handling, resampling, and statistic computation. This page outlines the most common workflows.</p>"},{"location":"usage/#working-with-atlases-and-lookup-tables","title":"Working with atlases and lookup tables","text":"<p>You can provide atlas metadata in multiple ways:</p> <ul> <li>Lookup table: pass a TSV file or <code>pandas.DataFrame</code> with <code>index</code> and <code>label</code> columns. Missing columns raise a <code>MissingLUTColumnsError</code>.</li> <li>Custom label selection: supply a list or mapping of label IDs via <code>labels</code> to restrict the analysis to specific parcels.</li> <li>Built-in masks: set <code>mask=\"gm\"</code>, <code>\"wm\"</code>, or <code>\"brain\"</code> to leverage MNI152 tissue masks from nilearn. Custom mask images are also supported.</li> </ul> <pre><code>from parcellate import VolumetricParcellator\n\nparcellator = VolumetricParcellator(\n    atlas_img=\"atlas.nii.gz\",\n    lut=\"atlas_lut.tsv\",\n    mask=\"gm\",  # use MNI152 grey-matter mask\n    resampling_target=\"data\",\n)\n</code></pre>"},{"location":"usage/#running-a-parcellation","title":"Running a parcellation","text":"<ol> <li>Fit the parcellator to set up the atlas grid and resampling strategy.</li> <li>Transform scalar images to compute parcel-wise statistics.</li> </ol> <pre><code>parcellator.fit(\"subject_T1w.nii.gz\")\nregional_stats = parcellator.transform(\"subject_T1w.nii.gz\")\n\nprint(regional_stats.columns)\n# index, label, volume_mm3, voxel_count, mean, std, ...\n</code></pre> <p>If <code>transform</code> is called before <code>fit</code>, a <code>ParcellatorNotFittedError</code> is raised to prevent accidental misuse.</p>"},{"location":"usage/#selecting-a-statistics-tier","title":"Selecting a statistics tier","text":"<p><code>parcellate</code> ships with 45 built-in statistics organized into named tiers. Use <code>stat_tier</code> to control how many are computed:</p> Tier Statistics Use case <code>core</code> 6 Fast exploration, large cohorts <code>extended</code> 21 Production pipelines <code>diagnostic</code> (default) 45 Quality control, distribution inspection <pre><code>from parcellate import VolumetricParcellator\n\nparcellator = VolumetricParcellator(\n    atlas_img=\"atlas.nii.gz\",\n    lut=\"atlas_lut.tsv\",\n    stat_tier=\"extended\",  # 21 statistics\n)\nparcellator.fit(\"subject_T1w.nii.gz\")\ndf = parcellator.transform(\"subject_T1w.nii.gz\")\n# df has columns: index, label, mean, std, median, volume_mm3, ...\n</code></pre> <p>For a full description of every statistic, see the Metrics reference.</p>"},{"location":"usage/#customizing-statistics","title":"Customizing statistics","text":"<p>Supply your own mapping of statistic names to callables to extend or replace the defaults. When <code>stat_functions</code> is provided it takes precedence over <code>stat_tier</code>.</p> <pre><code>import numpy as np\n\ncustom_stats = {\n    \"nanmedian\": np.nanmedian,\n    \"z_filtered_mean\": lambda values: float(np.nanmean(values[np.abs(values) &lt; 3])),\n}\n\nparcellator = VolumetricParcellator(\n    atlas_img=\"atlas.nii.gz\",\n    stat_functions=custom_stats,\n)\n</code></pre> <p>Each statistic receives the parcel's voxel values as a 1-D NumPy array. To access the scalar image (for example, to compute voxel volume), set <code>requires_image=True</code> on a :class:<code>parcellate.metrics.base.Statistic</code> instance.</p>"},{"location":"usage/#resampling-behavior","title":"Resampling behavior","text":"<p>Use <code>resampling_target</code> to control how atlases and scalar maps are aligned:</p> <ul> <li><code>\"data\"</code> (default) resamples the atlas to the scalar image grid using nearest-neighbor interpolation.</li> <li><code>\"labels\"</code> resamples scalar maps to the atlas grid, preserving atlas topology at the cost of interpolating intensities.</li> <li><code>None</code> keeps both images on their native grids; set this only when inputs already align.</li> </ul> <p>The helper methods <code>_prepare_map</code> and <code>_apply_mask_to_atlas</code> encapsulate the resampling steps and mask application, ensuring consistent background handling via <code>background_label</code>.</p>"},{"location":"usage/#probabilistic-4d-atlases","title":"Probabilistic (4D) atlases","text":"<p>Some atlases encode each region as a continuous probability map in a separate 3D volume, rather than assigning a single integer label per voxel. Examples include XTRACT white-matter tracts and the Harvard-Oxford cortical atlas. <code>parcellate</code> handles these natively \u2014 just pass the 4D NIfTI and the API stays the same.</p> <p>How it works</p> <p>Each volume in the 4D image corresponds to one region. Volume index 0 (zero-based) maps to region index 1 (one-based) in the output table, volume 1 maps to region 2, and so on. Within each volume, voxels whose probability is strictly greater than <code>atlas_threshold</code> are included in that region's statistics, so voxels can belong to more than one region simultaneously.</p> <p>Parameters</p> <ul> <li><code>atlas_threshold</code> (float, default <code>0.0</code>) \u2014 minimum probability to include a voxel. The comparison is strict (<code>&gt;</code>), so a voxel with probability exactly equal to the threshold is excluded. Set to <code>0.0</code> to include every non-zero voxel.</li> </ul> <p>Output filename entity</p> <p>When <code>atlas_threshold &gt; 0</code>, the value is embedded in the output filename as the BIDS-style entity <code>atlasthr-&lt;value&gt;</code> (e.g., <code>atlasthr-0.25</code>). The entity is omitted when the threshold is zero.</p> <pre><code>from parcellate import VolumetricParcellator\n\n# 4D probabilistic atlas \u2014 detected automatically\nparcellator = VolumetricParcellator(\n    atlas_img=\"xtract_tracts.nii.gz\",\n    lut=\"xtract_lut.tsv\",\n    atlas_threshold=0.25,  # keep only high-confidence voxels\n)\nparcellator.fit(\"subject_FA.nii.gz\")\nregional_stats = parcellator.transform(\"subject_FA.nii.gz\")\n# regional_stats contains one row per tract (region)\n</code></pre>"},{"location":"usage/#mask-thresholding","title":"Mask thresholding","text":"<p>When supplying a probabilistic brain mask (e.g., a grey-matter partial-volume estimate), you may want to restrict the analysis to voxels with a high tissue probability rather than any non-zero value.</p> <p>Parameters</p> <ul> <li><code>mask_threshold</code> (float, default <code>0.0</code>) \u2014 minimum mask value to keep a voxel. Strict <code>&gt;</code> comparison; voxels equal to the threshold are excluded. The default of <code>0.0</code> preserves the pre-v0.2.0 behaviour of including all non-zero mask voxels.</li> </ul> <p>Output filename entity</p> <p>When <code>mask_threshold &gt; 0</code>, the value appears as <code>maskthr-&lt;value&gt;</code> in the output filename. The entity is omitted when the threshold is zero.</p> <p>Environment variable</p> <p>When using the <code>parcellate-cat12</code> standalone CLI, set <code>MASKING_THRESHOLD</code> to supply the threshold without editing config files.</p> <pre><code>from parcellate import VolumetricParcellator\n\nparcellator = VolumetricParcellator(\n    atlas_img=\"atlas.nii.gz\",\n    mask=\"gm\",           # MNI152 grey-matter probability map\n    mask_threshold=0.5,  # include only voxels where GM probability &gt; 0.5\n)\nparcellator.fit(\"subject_T1w.nii.gz\")\nregional_stats = parcellator.transform(\"subject_T1w.nii.gz\")\n</code></pre>"}]}